<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Spice.ai blog – data</title><link>/categories/data/</link><description>Recent content in data on Spice.ai blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 10 May 2022 00:00:00 +0000</lastBuildDate><atom:link href="/categories/data/index.xml" rel="self" type="application/rss+xml"/><item><title>Posts: Building on Apache Arrow and Flight</title><link>/posts/2022/05/10/building-on-apache-arrow-and-flight/</link><pubDate>Tue, 10 May 2022 00:00:00 +0000</pubDate><guid>/posts/2022/05/10/building-on-apache-arrow-and-flight/</guid><description>
&lt;p>In February, we announced &lt;a href="https://blog.spiceai.org/posts/2022/02/08/announcing-the-release-of-spice.ai-v0.6-alpha/">Spice.ai OSS v0.6&lt;/a> with its data processing and transport completely rebuilt upon Apache &lt;a href="https://arrow.apache.org/blog/2019/10/13/introducing-arrow-flight/">Flight&lt;/a>. This enables &lt;a href="https://spiceai.org">Spice.ai OSS&lt;/a> to scale to datasets 10-100 times larger and brings Spice.ai into the &lt;a href="https://arrow.apache.org/">Apache Arrow ecosystem&lt;/a> paving the way for integrations with many &lt;a href="https://arrow.apache.org/powered_by/">popular projects&lt;/a>, like &lt;a href="https://parquet.apache.org/">Apache Parquet&lt;/a>, &lt;a href="https://pandas.pydata.org/">pandas&lt;/a> and big data systems like Hive, Drill, Spark, Snowflake, BigQuery, and many more.&lt;/p>
&lt;p>In &lt;a href="https://blog.spiceai.org/posts/2022/04/21/announcing-the-release-of-spice.ai-v0.6.1-alpha/">Spice.ai OSS v0.6.1&lt;/a> we announced a new big data system integration… our own, &lt;a href="https://spice.xyz">Spice.xyz&lt;/a>!&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 10px;">
&lt;div style="display: flex; flex-direction: column; text-align: center;">
&lt;img style="max-width: 600px; margin: auto" src="https://user-images.githubusercontent.com/80174/167584679-115c26ff-74ea-48b7-9c26-4bd4feae2afa.jpg" />
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Figure 1. Spice.xyz - Data and AI infrastructure for web3&lt;/div>
&lt;/div>
&lt;/div>
&lt;h3 id="integration-with-spicexyz">Integration with Spice.xyz&lt;/h3>
&lt;p>&lt;a href="https://spice.xyz">Spice.xyz&lt;/a> is data and AI infrastructure for web3.&lt;/p>
&lt;p>It’s web3 data made easy. Insanely fast and purpose designed for applications and ML.&lt;/p>
&lt;p>Spice.xyz delivers data in &lt;a href="https://arrow.apache.org/">Apache Arrow&lt;/a> format, over high-performance &lt;a href="https://arrow.apache.org/blog/2019/10/13/introducing-arrow-flight/">Apache Arrow Flight APIs&lt;/a> to your application, notebook, ML pipeline, and of course, to the Spice.ai runtime.&lt;/p>
&lt;p>With &lt;a href="https://blog.spiceai.org/posts/2022/04/21/announcing-the-release-of-spice.ai-v0.6.1-alpha/">Spice.ai OSS v0.6.1&lt;/a>, a new &lt;a href="https://https://github.com/spiceai/data-components-contrib/tree/trunk/dataconnectors/arrow-flight">Apache Arrow Flight data connector&lt;/a> was made available, creating a high-performance bulk-data transport directly into the Spice.ai ML engine. Coupled with Spice.xyz, developers can quickly and easily build web3 data-driven applications that learn and adapt using Spice.ai.&lt;/p>
&lt;p>To read the announcement post for &lt;a href="https://spice.xyz">Spice.xyz&lt;/a>, visit &lt;a href="https://medium.com/spice-ai/announcing-spice-xyz-94323159cd2b">blog.spice.xyz&lt;/a>.&lt;/p>
&lt;h3 id="apache-arrow-and-flight-core">Apache Arrow and Flight Core&lt;/h3>
&lt;p>&lt;a href="https://arrow.apache.org/">Apache Arrow&lt;/a> is a specification for an in-memory columnar data format that’s very efficient for analytics operations. Arrow’s zero-copy read semantics coupled with the &lt;a href="https://arrow.apache.org/blog/2019/10/13/introducing-arrow-flight/">Flight&lt;/a> client-server framework mean extremely fast and efficient data transport and access without serialization overhead. This enables high-performance bulk-data scenarios, critical for data-driven applications and ML. These properties enable an open-architecture based on Apache Arrow, Flight, and Parquet.&lt;/p>
&lt;p>Paul Dix, CTO of InfluxData wrote a fantastic post on the &lt;a href="https://www.influxdata.com/blog/apache-arrow-parquet-flight-and-their-ecosystem-are-a-game-changer-for-olap/">Arrow ecosystem&lt;/a> and why the &lt;a href="https://www.influxdata.com/blog/announcing-influxdb-iox/">future core of InfluxDB is built with Arrow&lt;/a>. Sam Crowder also wrote &lt;a href="https://cloudconstructed.substack.com/p/a-recent-history-of-batch-data?s=r">A (Recent) History of Batch Data&lt;/a> showing how Arrow is a cornerstone of modern data architecture.&lt;/p>
&lt;p>Joining projects like InfluxDB, the core of both &lt;a href="https://spiceai.org">Spice.ai OSS&lt;/a> and &lt;a href="https://spice.xyz">Spice.xyz&lt;/a> are built with a foundation of Arrow and Flight. This means they benefit from the same high-performance data operations, they work great with each other and other projects in the ecosystem.&lt;/p>
&lt;h3 id="exciting-new-use-cases">Exciting New Use Cases&lt;/h3>
&lt;p>Betting on Arrow in Spice.ai enables exciting new applications because &lt;a href="https://blog.spiceai.org/posts/2021/12/05/ai-needs-ai-ready-data/">AI needs AI-ready data&lt;/a>.&lt;/p>
&lt;p>Previously it was difficult to efficiently get bulk data from a provider like Spice.xyz to the Spice.ai engine, but now it&amp;rsquo;s just a matter of configuring the connection through &lt;a href="https://github.com/spiceai/data-components-contrib/blob/trunk/dataconnectors/flight/README.md">a few lines of YAML&lt;/a>.&lt;/p>
&lt;p>Imagine creating an application to trade NFTs. With Spice.xyz, developers can query Ethereum for data relating to NFT trading activity. That data is then delivered with the high-performance Arrow format to the Spice.ai runtime. The application’s Spicepod could learn how to value NFTs based upon it’s trading history and the communities it’s owners have been engaged in. And this could be all done in real-time, something not feasible before.&lt;/p>
&lt;p>In addition, using the Arrow Flight connector, other exciting applications are enabled across a ton of domains, like IoT, financial applications, security monitoring, and many more.&lt;/p>
&lt;h3 id="whats-next">What&amp;rsquo;s Next&lt;/h3>
&lt;p>To get somewhere you need a goal or destination, a vehicle to get there, and fuel for that vehicle.&lt;/p>
&lt;p>When it comes to intelligent, AI-driven applications, &lt;a href="https://spice.xyz">Spice.xyz&lt;/a> now provides the Spice.ai vehicle with a massive pipeline of web3 data fuel.&lt;/p>
&lt;p>The next step is to make it easier for developers to define the destination for the vehicle. Upcoming on the &lt;a href="https://github.com/spiceai/spiceai/blob/trunk/docs/ROADMAP.md">Spice.ai OSS roadmap&lt;/a> is the ability for developers to define goals for how the decision-engine should learn. Like learning to maximize measurement “A” or optimizing to a target of “B”.&lt;/p>
&lt;p>For example, in web3, this might be to build a client that can learn and adapt to optimize Ethereum Gas Fee prices for token swaps. The goal would be to minimize the gas fee, a problem we experienced first-hand when we built &lt;a href="https://defly.ai">defly.ai&lt;/a>. Today you have to encode that goal into your &lt;a href="https://docs.spiceai.org/concepts/rewards/">reward function&lt;/a>, but our plan is to help do that for you, and all you have to do is tell us the end goal.&lt;/p>
&lt;p>Goal-oriented learning applies to many domains, whether it be minimizing fees in crypto or maximizing engagement on a social platform. And personally, we’re excited about the eventual ability to apply Spice.ai and just say “minimize my taxes” :-)&lt;/p>
&lt;h3 id="learn-more-and-contribute">Learn More and Contribute&lt;/h3>
&lt;p>Even for advanced developers, building intelligent apps that leverage AI is still way too hard. Our mission is to make this as easy as creating a modern web page. If that vision resonates with you, join us!&lt;/p>
&lt;p>If you’d like to get involved, we’d love to talk. Try out &lt;a href="http://Spice.ai">Spice.ai OSS&lt;/a>, &lt;a href="https://spice.xyz">Spice.xyz&lt;/a>, &lt;a href="mailto:hey@spiceai.io?subject=hey">email us “hey,”&lt;/a> get in touch on &lt;a href="https://discord.gg/kZnTfneP5u">Discord&lt;/a>, or reach out on &lt;a href="https://twitter.com/spiceaihq">Twitter&lt;/a>.&lt;/p>
&lt;p>Luke&lt;/p></description></item><item><title>Posts: What Data Informs AI-driven Decision Making?</title><link>/posts/2022/01/04/what-data-informs-ai-driven-decision-making/</link><pubDate>Tue, 04 Jan 2022 00:00:00 +0000</pubDate><guid>/posts/2022/01/04/what-data-informs-ai-driven-decision-making/</guid><description>
&lt;p>AI unlocks a new generation of intelligent &lt;a href="https://blog.spiceai.org/posts/2021/11/05/making-apps-that-learn-and-adapt/">applications that learn and adapt&lt;/a> from data. These applications use machine learning (ML) to out-perform traditionally developed software. However, the data engineering required to leverage ML is a significant challenge for many product teams. In this post, we&amp;rsquo;ll explore the three classes of data you need to build next-generation applications and how Spice.ai handles runtime data engineering for you.&lt;/p>
&lt;p>While ML has many different applications, one way to think about ML in a real-time application that can adapt is as a decision engine. Phillip discussed decision engines and their potential uses in &lt;a href="https://blog.spiceai.org/posts/2021/12/30/a-new-class-of-applications-that-learn-and-adapt/">A New Class of Applications That Learn and Adapt&lt;/a>. This decision engine learns and informs the application how to operate. Of course, applications can and do make decisions without ML, but a developer normally has to code that logic. And the intelligence of that code is fixed, whereas ML enables a machine to constantly find the appropriate logic and evolve the code as it learns. For ML to do this, it needs three classes of data.&lt;/p>
&lt;h3 id="the-three-classes-of-data-for-informed-decision-making">The three classes of data for informed decision making&lt;/h3>
&lt;p>We don&amp;rsquo;t want any decision, though. We want high-quality, informed decisions. If you consider making higher quality, informed decisions over time, you need three classes of information. These classes are historical information, real-time or present information, and the results of your decisions.&lt;/p>
&lt;p>Especially recently, stock or crypto trading is something many of us can relate to. To make high-quality, informed investing decisions, you first need general historical information on the price, security, financials, industry, previous trades, etc. You study this information and learn what might make a good investment or trade.&lt;/p>
&lt;p>Second, you need a real-time updated stream of data as it happens to make a decision. If you were stock trading, this information might be the stock price on the day or hour you want to make the trade. You need to apply what you learned from historical data to the current information to decide what trade to place.&lt;/p>
&lt;p>Finally, if we&amp;rsquo;re going to make better decisions over time, we need to capture and learn from the results of those decisions. Whether you make a great or poor trade, you want to incorporate that experience into your historical learning.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px; margin-bottom: 20px;">
&lt;div style="display: grid;">
&lt;img style="max-width: 600px; margin: auto" alt="Three data classes." src="https://user-images.githubusercontent.com/80174/147721731-d7f6a414-1b8c-44cb-83ef-9cca0bc65b61.png">
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Figure 1. The three data classes.&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>Using all three data classes together results in higher quality decisions over time. Broad data across these classes are useful, and we could make some nice trades with that. Still, we can make an even higher quality trading decision with personal context. For example, we may want to consider the individual tax consequences or risk level of the trade for our situation. So each of these classes also comes with global or local variants. We combine global information, like what worked well for everyone, and local experience, what worked well for us and our situation, to make the best, overall informed decision.&lt;/p>
&lt;h3 id="the-waterfall-approach-to-data-engineering">The waterfall approach to data engineering&lt;/h3>
&lt;p>Consider how you would capture these three data classes and make them available to both the application and ML in the trading example. This data engineering can be a pretty big challenge.&lt;/p>
&lt;p>First, you need a way to gather and consume historical information, like stock prices, and keep that updated over time. You need to handle streaming constantly updated real-time data to make runtime decisions on how to operate. You need to capture and match the decisions you make and feed that back into learning. And finally, you need a way to provide personal or local context, like holding off on sell trades until next year, to stay within a tax threshold, or identifying a pattern you like to trade. If all this wasn&amp;rsquo;t enough, as we learned from Phillip&amp;rsquo;s &lt;a href="https://blog.spiceai.org/posts/2021/12/05/ai-needs-ai-ready-data/">AI needs AI-ready data&lt;/a> post, all three data classes need to be in a format that ML can use.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px; margin-bottom: 20px;">
&lt;div style="display: grid;">
&lt;img style="max-width: 600px; margin: auto" alt="Traditional app and data integration." src="https://user-images.githubusercontent.com/80174/147722263-26333f5e-2da0-4c8c-a042-0c88c37d59be.png">
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Figure 2. Traditional app and data integration.&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>If you can afford a data or ML team, they may do much of this for you. However, this model starts to look quite waterfall-like and is not suited well to applications that want to learn and adapt in real-time. Like a waterfall approach, you would provide requirements to your data team, and they would do the data engineering required to provide you with the first two classes of data, historical and real-time. They may give you ML-ready data or train an ML model for you. However, there is often a large latency to apply that data or model in your application and a long turn-around time if it does not meet your requirements. In addition, to capture the third class of data, you would need to capture and send the results of the decisions your application made as a result of using those models back to the data team to incorporate in future learning. This latency through the data, decision-making, learning, and adaptation process is often infeasible for a real-world app.&lt;/p>
&lt;p>And, if you can&amp;rsquo;t afford a data team, you have to figure out how to do all that yourself.&lt;/p>
&lt;h3 id="the-agile-approach">The agile approach&lt;/h3>
&lt;p>Modern software engineering practices have favored agile methodologies to reduce time to learn and adapt applications to customer and business needs. Spice.ai takes inspiration from agile methods to provide developers with a fast, iterative development cycle.&lt;/p>
&lt;p>Spice.ai provides mechanisms for making all three classes of data available to both the application and the decision engine. Developers author Spicepods declaring how data should be captured, consumed, and made ML-ready so that all three classes are consistent and ML available.&lt;/p>
&lt;p>The Spice.ai runtime exposes developer-friendly APIs and data connectors for capturing and consuming data and annotating that data with personal context. The runtime generates AI-ready data for you and makes it available directly for ML. These APIs also make it easy to capture application decisions and incorporate the resulting learning.&lt;/p>
&lt;p>The Spice.ai approach short circuits the traditional waterfall-like data process by keeping as much data as possible application local instead of round-tripping through an external pipeline or team, especially valuable for real-time data. The application can learn and adapt faster by reducing the latency of decision consequences to learning.&lt;/p>
&lt;p>Spice.ai enables personalized learning from personal context and experiences through the interpretations mechanism. Interpretations allow an application to provide additional information or an &amp;ldquo;interpretation&amp;rdquo; of a time range as input to learning. The trading example could be as simple as labeling a time range as a good time to buy or providing additional contextual information such as tax considerations, etc. Developers can also use interpretations to record the results of decisions with more context than what might be available in the observation space. You can read more about Interpretations in the &lt;a href="https://docs.spiceai.org/concepts/interpretations/">Spice.ai docs&lt;/a>.&lt;/p>
&lt;p>While Spice.ai focuses on ensuring consistent ML-ready data is available, it does not replace traditional data systems or teams. They still have their place, especially for large historical datasets, and Spice.ai can consume data produced by them. Where possible, especially for application and real-time data, Spice.ai keeps runtime data local to create a virtuous cycle of data from the application to the decision engine and back again, enabling faster and more agile learning and adaption.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px; margin-bottom: 20px;">
&lt;div style="display: grid;">
&lt;img style="max-width: 600px; margin: auto" alt="App with Spice.ai." src="https://user-images.githubusercontent.com/80174/147721797-707d29b2-f93e-42be-809a-921349049895.png">
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Figure 3. App with Spice.ai.&lt;/div>
&lt;/div>
&lt;/div>
&lt;h3 id="summary">Summary&lt;/h3>
&lt;p>In summary, to build an intelligent application driven from AI recommended decisions, a significant amount of data engineering can be required to learn, make decisions, and incorporate the results. The Spice.ai runtime enables you as a developer to focus on consuming those decisions and tuning how the AI engine should learn rather than the runtime data engineering.&lt;/p>
&lt;p>The potential of the next generation of intelligent applications to improve the quality of our lives is very exciting. Using AI to help applications make better decisions, whether that be AI-assisted investing, improving the energy efficiency of our homes and buildings, or supporting us in deciding on the most appropriate medical treatment, is very promising.&lt;/p>
&lt;h3 id="learn-more-and-contribute">Learn more and contribute&lt;/h3>
&lt;p>Even for advanced developers, building intelligent apps that leverage AI is still way too hard. Our mission is to make this as easy as creating a modern web page. If that vision resonates with you, join us!&lt;/p>
&lt;p>If you want to get involved, we&amp;rsquo;d love to talk. Try out &lt;a href="https://spiceai.org">Spice.ai&lt;/a>, &lt;a href="mailto:hey@spice.ai">email us&lt;/a> &amp;ldquo;hey,&amp;rdquo; get in touch on &lt;a href="https://discord.gg/kZnTfneP5u">Discord&lt;/a>, or reach out on &lt;a href="https://twitter.com/spice_ai">Twitter&lt;/a>.&lt;/p>
&lt;p>Luke&lt;/p></description></item><item><title>Posts: AI needs AI-ready data</title><link>/posts/2021/12/05/ai-needs-ai-ready-data/</link><pubDate>Sun, 05 Dec 2021 00:00:00 +0000</pubDate><guid>/posts/2021/12/05/ai-needs-ai-ready-data/</guid><description>
&lt;p>A significant challenge when developing an app powered by AI is providing the machine learning (ML) engine with data in a format that it can use to learn. To do that, you need to normalize the numerical data, one-hot encode categorical data, and decide what to do with incomplete data - among other things.&lt;/p>
&lt;p>This data handling is often challenging! For example, to learn from Bitcoin price data, the prices are better if normalized to a range between -1 and 1. Being close to 0 is also a problem because of the lack of precision in floating-point representations (usually under 1e-5).&lt;/p>
&lt;p>As a developer, if you are new to AI and machine learning, a great talk that explains the basics is &lt;a href="https://www.youtube.com/watch?v=VwVg9jCtqaU">Machine Learning Zero to Hero&lt;/a>. Spice.ai makes the process of getting the data into an AI-ready format easy by doing it for you!&lt;/p>
&lt;h2 id="what-is-ai-ready-data">What is AI-ready data?&lt;/h2>
&lt;p>You write code with if statements and functions, but your machine only understands 1s and 0s. When you write code, you leverage tools, like a compiler, to translate that human-readable code into a machine-readable format.&lt;/p>
&lt;p>Similarly, data for AI needs to be translated or &amp;ldquo;compiled&amp;rdquo; to be understood by the ML engine. You may have heard of &lt;a href="https://www.tensorflow.org/guide/tensor">tensors&lt;/a> before; they are simply another word for a multi-dimensional array and they are the language of ML engines. All inputs to and all outputs from the engine are in tensors. You could use the following techniques when converting (or &amp;ldquo;compiling&amp;rdquo;) source data to a tensor.&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Normalization/standardization of the numerical input data.&lt;/strong> Many of the inputs and outputs in machine learning are interpreted as probability distributions. Much of the math that powers machine learning, such as softmax, tanh, sigmoid, etc., is meant to work in the [-1, 1] range.&lt;/li>
&lt;/ol>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: grid;">
&lt;img style="max-width: 563px; margin: auto" alt="Normalizing raw data" src="https://user-images.githubusercontent.com/879445/144733722-46baa2f7-5e94-4113-9770-735987d6a390.png">
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Figure 1. Normalizing Bitcoin price data.&lt;/div>
&lt;/div>
&lt;/div>
&lt;ol start="2">
&lt;li>&lt;strong>Conversion of categorical data into numerical data.&lt;/strong> For categorical data (i.e., colors such as &amp;ldquo;red,&amp;rdquo; &amp;ldquo;blue,&amp;rdquo; or &amp;ldquo;green&amp;rdquo;), you can achieve this through a technique called &lt;a href="https://www.educative.io/blog/one-hot-encoding">&amp;ldquo;One Hot Encoding.&amp;rdquo;&lt;/a> In one hot encoding, each possible value in the category appears as a column. The values in the column are assigned a binary value of 1 or 0 depending on whether the value exists or not.&lt;/li>
&lt;/ol>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 300px; margin: auto" src="https://user-images.githubusercontent.com/879445/144733213-bd162dc0-7ac9-4bbb-9115-1dc46d2084cf.png" />
&lt;div style="font-size: 0.8rem; font-style: italic;">Figure 2. A visualization of one-hot encoding&lt;/div>
&lt;/div>
&lt;/div>
&lt;ol start="3">
&lt;li>Several advanced techniques exist for &amp;ldquo;compiling&amp;rdquo; this source data - this process is known in the AI world as &amp;ldquo;feature engineering.&amp;rdquo; &lt;a href="https://developers.google.com/machine-learning/crash-course/representation/feature-engineering">This article&lt;/a> goes into more detail on feature engineering techniques if you are interested in learning more.&lt;/li>
&lt;/ol>
&lt;p>There are excellent tools like &lt;a href="https://pandas.pydata.org/">Pandas&lt;/a>, &lt;a href="https://numpy.org/">Numpy&lt;/a>, &lt;a href="https://scipy.org/">scipy&lt;/a>, and others that make the process of data transformation easier. However, most of these tools are Python libraries and frameworks - which means having to learn Python if you don&amp;rsquo;t know it already. Plus, when building intelligent apps (instead of just doing pure data analysis), this all needs to work on real-time data in production.&lt;/p>
&lt;h2 id="building-intelligent-apps">Building intelligent apps&lt;/h2>
&lt;p>The tools mentioned above are not designed for building real-time apps. They are often designed for analytics/data science.&lt;/p>
&lt;p>In your app, you will need to do this data compilation in real-time - and you can&amp;rsquo;t rely on a local script to help process your data.
It becomes trickier if the team responsible for the initial training of the machine learning model is not the team responsible for deploying it out into production.&lt;/p>
&lt;p>How data is loaded and processed in a static dataset is likely very different from how the data is loaded and processed in real-time as your app is live. The result often is two separate codebases that are maintained by different teams that are both responsible for doing the same thing! Ensuring that those codebases stay consistent and evolve together is another challenge to tackle.&lt;/p>
&lt;h2 id="spiceai-helps-developers-build-apps-with-real-time-ml">Spice.ai helps developers build apps with real-time ML&lt;/h2>
&lt;p>Spice.ai handles the &amp;ldquo;compilation&amp;rdquo; of data for you.&lt;/p>
&lt;p>You specify the data that your ML should learn from in a &lt;a href="https://blog.spiceai.org/posts/2021/12/02/spicepods-from-zero-to-hero/">Spicepod&lt;/a>. The Spice.ai runtime handles the logistics of gathering the data and compiling it into an AI-ready format.&lt;/p>
&lt;p>It does this by using many techniques described earlier, such as normalization and one-hot encoding. And because we&amp;rsquo;re continuing to evolve Spice.ai, our data compilation will only get better over time.&lt;/p>
&lt;p>In addition, the design of the Spice.ai runtime naturally ensures that the data used for both the training and real-time cases are consistent. Spice.ai uses the same data-components and runtime logic to produce the data. And not only that, you can take this a step further and share your Spicepod with someone else, and they would be able to use the same AI-ready data for their applications.&lt;/p>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;p>Spice.ai handles the process of compiling your data into an AI-ready format in a way that is consistent both during the training and real-time stages of the ML engine. A Spicepod defines which data to get and where to get it. Sharing this Spicepod allows someone else to use the same AI-ready data format in their application.&lt;/p>
&lt;h3 id="learn-more-and-contribute">Learn more and contribute&lt;/h3>
&lt;p>Building intelligent apps that leverage AI is still way too hard, even for advanced developers. Our mission is to make this as easy as creating a modern web page. If the vision resonates with you, join us!&lt;/p>
&lt;p>Our &lt;a href="https://github.com/spiceai/spiceai/blob/trunk/docs/ROADMAP.md">Spice.ai Roadmap&lt;/a> is public, and now that we have launched, the project and work are open for collaboration.&lt;/p>
&lt;p>If you are interested in partnering, we&amp;rsquo;d love to talk. Try out &lt;a href="https://spiceai.org">Spice.ai&lt;/a>, &lt;a href="mailto:hey@spice.ai">email us&lt;/a> &amp;ldquo;hey,&amp;rdquo; get in touch on &lt;a href="https://discord.gg/kZnTfneP5u">Discord&lt;/a>, or reach out on &lt;a href="https://twitter.com/spice_ai">Twitter&lt;/a>.&lt;/p>
&lt;p>We are just getting started! 🚀&lt;/p>
&lt;p>Phillip&lt;/p></description></item></channel></rss>