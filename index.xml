<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Spice.ai blog â€“ Spice.ai Blog</title><link>/</link><description>Recent content in Spice.ai Blog on Spice.ai blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="/index.xml" rel="self" type="application/rss+xml"/><item><title>Posts: Adding Soft Actor-Critic</title><link>/posts/2022/01/12/adding-soft-actor-critic/</link><pubDate>Wed, 12 Jan 2022 00:00:00 +0000</pubDate><guid>/posts/2022/01/12/adding-soft-actor-critic/</guid><description>
&lt;p>Last month in the v0.5-alpha version, a new learning algorithm was added to Spice.ai: Soft Actor-Critic. This is a very popular algorithm in the Reinforcement Learning field. Let&amp;rsquo;s see what it is and why this is an interesting addition.&lt;/p>
&lt;p>The previous article &lt;a href="/posts/2021/12/15/understanding-q-learning-how-a-reward-is-all-you-need/">Understanding Q-learning: How a Reward Is All You Need&lt;/a> is not necessary but can be helpful to understand this article.&lt;/p>
&lt;h2 id="what-is-soft-actor-critic">What is Soft Actor-Critic&lt;/h2>
&lt;h3 id="actor-critic">Actor-Critic&lt;/h3>
&lt;p>Deepmind first introduced the actor-critic approach in deep learning in a &lt;a href="https://arxiv.org/abs/1602.01783">2016 paper&lt;/a>. We can think of this approach as having 2 tasks:&lt;/p>
&lt;ul>
&lt;li>Choosing actions to take: giving probabilities for each possible action (the policy)&lt;/li>
&lt;li>Evaluating values for each action: the estimated reward from those actions (the Q-values)&lt;/li>
&lt;/ul>
&lt;p>Those tasks will be made by 2 different neural networks or a single network that branches out in 2 heads. The actor is the part that outputs the policy, while the critic outputs the values.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 300px; margin: auto" alt="Actor-Critic Diagram" src="https://user-images.githubusercontent.com/19952490/148524970-e5fab55c-7364-4cb9-870c-7f5b8b58cc6f.png">
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Figure 1. Actor-Critic struture&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>In most cases, this model was proven to perform very well, better than Deep Q-Learning. The actor is trained to prefer actions associated with the best values from the critic. The critic is trained to correctly estimate rewards (current and future ones) of the actions.&lt;/p>
&lt;p>Both will improve over time though we have to keep in mind that the critic is unlikely to evaluate all possible actions in the environment as it will only see actions from states that the actor is likely to take (the policy).&lt;/p>
&lt;p>This bias of the system toward its policy is important: the algorithm is meant to train &lt;em>on-policy&lt;/em>. The duo actor-critic works together: trying to train it with inputs and outputs from another system (humans or even itself in past iterations of its own training) will not work.&lt;/p>
&lt;p>Multiple improvements were made to limit the bias of the actor-critic approach but the necessity to train on-policy remains. This is very limiting as being able to train from any experience can be very valuable for time and data efficiency.&lt;/p>
&lt;h3 id="soft-actor-critic">Soft Actor-Critic&lt;/h3>
&lt;p>Soft Actor-Critic allows an Actor-Critic network to train off-policy. It was introduced in &lt;a href="https://arxiv.org/abs/1801.01290">a paper&lt;/a> in 2018 and included multiple additions to improve its parent algorithm. The main difference is the introduction of the entropy of the actor outputs during the training phase.&lt;/p>
&lt;p>The entropy measures the chaos/order of a system (or uncertainty). If a system always acts the same way, the entropy is minimal. Here the actor&amp;rsquo;s entropy is maximum if all possible actions have the same weight (same probability) and minimum if the actor always chose only a single action with 100% confidence.&lt;/p>
&lt;p>During the training phase, the actor is trained to maintain the entropy of its outputs at a specific value.&lt;/p>
&lt;p>The introduction of the entropy changes the goal of the training not only to find the bests output but to keep exploring the other actions. The critic part will be trained on all actions, even if they may occur only in rare cases.&lt;/p>
&lt;p>There are other essential parts, such as having 2 critics and being able to output continuous values, but the entropy is the crucial difference in this algorithm&amp;rsquo;s training and potential.&lt;/p>
&lt;h2 id="adding-choices-to-spiceai-learning-algorithms">Adding choices to Spice.AI learning algorithms&lt;/h2>
&lt;p>As we saw above, the Actor-Critic algorithm is known to outperform Deep Q-Learning in most cases. If we also want to leverage previous data (off-policy training), Soft Actor-Critic is a natural choice. This approach is heavier despite better theoretical results, making it more suitable for complex tasks. For simpler tasks, Deep Q-Learning will still be an appealing option for its speed of training and its capability to quickly convergence to a good solution.&lt;/p>
&lt;p>We can think of Soft Actor-Critic as a complex machine designed to take actions while keeping a variety of possibilities. Sometimes several options seem equally rewarding: a simpler algorithm would take what it evaluates as the best one even though the margin is small and the precision of its evaluation shouldn&amp;rsquo;t be enough. This tendency to quickly convergence to a solution has its benefits and inconveniences.&lt;/p>
&lt;h2 id="implementation-in-the-source-code">Implementation in the source code&lt;/h2>
&lt;p>Adding new algorithms is essential to Spice.ai, so the procedure was designed to be straightforward.&lt;/p>
&lt;p>Looking a the &lt;a href="https://github.com/spiceai/spiceai">source code&lt;/a>, the code related to training agents is in the &lt;code>ai/src&lt;/code> folder. This part of the code uses the python language as most modern AI libraries are distributed in this language.&lt;/p>
&lt;p>In this folder, every agent is in the &lt;code>algorithms&lt;/code> folder, and each has its subfolder. There is an &lt;code>agent_interface&lt;/code> file that defines the main class that the different agents should inherit from and a &lt;code>factory&lt;/code> script responsible for creating instances of an agent from a given algorithm name.&lt;/p>
&lt;p>Adding a new agent is simple:&lt;/p>
&lt;ul>
&lt;li>making a new folder in the &lt;code>algorithms&lt;/code>&lt;/li>
&lt;li>adding a json file describing the &lt;code>algorithm_id&lt;/code>, &lt;code>name&lt;/code>, and &lt;code>docs_link&lt;/code> (see other json as an example) in the folder&lt;/li>
&lt;li>adding a new python file with a class that would inherit from the &lt;code>SpiceAIAgent&lt;/code> defined in the &lt;code>agent_interface&lt;/code> script&lt;/li>
&lt;li>adding a line in the &lt;code>factory&lt;/code> script to instantiate the new implementation when its name is called.&lt;/li>
&lt;/ul>
&lt;p>For the new agent, inheriting from the main &lt;code>SpiceAIAgent&lt;/code> class, 5 functions need to be implemented:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>add_experience&lt;/strong>: storing inputs and outputs (used during the training)&lt;/li>
&lt;li>&lt;strong>act&lt;/strong>: returning the action to be taken from a given input&lt;/li>
&lt;li>&lt;strong>save&lt;/strong>: saving the agent to a given a path&lt;/li>
&lt;li>&lt;strong>load&lt;/strong>: restoring the agent from a given path&lt;/li>
&lt;li>&lt;strong>learn&lt;/strong>: train iteration (from the accumulated experiences)&lt;/li>
&lt;/ul>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>Soft Actor-Critic is a fascinating algorithm that performs well in complex environments. We now &lt;a href="/posts/2021/12/06/announcing-the-release-of-spice.ai-v0.5-alpha/">support Soft Actor Critic&lt;/a> in Spice.ai, which is another step forward in constantly improving the performance of the AI engine. Additionally, we&amp;rsquo;ll continue improving existing algorithms and adding newer ones over time. We designed the platform for ease of implementation and experimentation so if you&amp;rsquo;d like to try building your own agent, you can get the source code on &lt;a href="https://github.com/spiceai/spiceai">Github&lt;/a> and contribute to the platform. Say hi on &lt;a href="https://discord.gg/kZnTfneP5u">Discord&lt;/a>, reach out on &lt;a href="https://twitter.com/SpiceAIHQ">Twitter&lt;/a> or &lt;a href="mailto:hey@spiceai.io">email us&lt;/a>.&lt;/p>
&lt;p>I hope you enjoy this post and something new.&lt;/p>
&lt;p>Corentin&lt;/p></description></item><item><title>Posts: What Data Informs AI-driven Decision Making?</title><link>/posts/2022/01/04/what-data-informs-ai-driven-decision-making/</link><pubDate>Tue, 04 Jan 2022 00:00:00 +0000</pubDate><guid>/posts/2022/01/04/what-data-informs-ai-driven-decision-making/</guid><description>
&lt;p>AI unlocks a new generation of intelligent &lt;a href="https://blog.spiceai.org/posts/2021/11/05/making-apps-that-learn-and-adapt/">applications that learn and adapt&lt;/a> from data. These applications use machine learning (ML) to out-perform traditionally developed software. However, the data engineering required to leverage ML is a significant challenge for many product teams. In this post, we&amp;rsquo;ll explore the three classes of data you need to build next-generation applications and how Spice.ai handles runtime data engineering for you.&lt;/p>
&lt;p>While ML has many different applications, one way to think about ML in a real-time application that can adapt is as a decision engine. Phillip discussed decision engines and their potential uses in &lt;a href="https://blog.spiceai.org/posts/2021/12/30/a-new-class-of-applications-that-learn-and-adapt/">A New Class of Applications That Learn and Adapt&lt;/a>. This decision engine learns and informs the application how to operate. Of course, applications can and do make decisions without ML, but a developer normally has to code that logic. And the intelligence of that code is fixed, whereas ML enables a machine to constantly find the appropriate logic and evolve the code as it learns. For ML to do this, it needs three classes of data.&lt;/p>
&lt;h3 id="the-three-classes-of-data-for-informed-decision-making">The three classes of data for informed decision making&lt;/h3>
&lt;p>We don&amp;rsquo;t want any decision, though. We want high-quality, informed decisions. If you consider making higher quality, informed decisions over time, you need three classes of information. These classes are historical information, real-time or present information, and the results of your decisions.&lt;/p>
&lt;p>Especially recently, stock or crypto trading is something many of us can relate to. To make high-quality, informed investing decisions, you first need general historical information on the price, security, financials, industry, previous trades, etc. You study this information and learn what might make a good investment or trade.&lt;/p>
&lt;p>Second, you need a real-time updated stream of data as it happens to make a decision. If you were stock trading, this information might be the stock price on the day or hour you want to make the trade. You need to apply what you learned from historical data to the current information to decide what trade to place.&lt;/p>
&lt;p>Finally, if we&amp;rsquo;re going to make better decisions over time, we need to capture and learn from the results of those decisions. Whether you make a great or poor trade, you want to incorporate that experience into your historical learning.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px; margin-bottom: 20px;">
&lt;div style="display: grid;">
&lt;img style="max-width: 600px; margin: auto" alt="Three data classes." src="https://user-images.githubusercontent.com/80174/147721731-d7f6a414-1b8c-44cb-83ef-9cca0bc65b61.png">
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Figure 1. The three data classes.&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>Using all three data classes together results in higher quality decisions over time. Broad data across these classes are useful, and we could make some nice trades with that. Still, we can make an even higher quality trading decision with personal context. For example, we may want to consider the individual tax consequences or risk level of the trade for our situation. So each of these classes also comes with global or local variants. We combine global information, like what worked well for everyone, and local experience, what worked well for us and our situation, to make the best, overall informed decision.&lt;/p>
&lt;h3 id="the-waterfall-approach-to-data-engineering">The waterfall approach to data engineering&lt;/h3>
&lt;p>Consider how you would capture these three data classes and make them available to both the application and ML in the trading example. This data engineering can be a pretty big challenge.&lt;/p>
&lt;p>First, you need a way to gather and consume historical information, like stock prices, and keep that updated over time. You need to handle streaming constantly updated real-time data to make runtime decisions on how to operate. You need to capture and match the decisions you make and feed that back into learning. And finally, you need a way to provide personal or local context, like holding off on sell trades until next year, to stay within a tax threshold, or identifying a pattern you like to trade. If all this wasn&amp;rsquo;t enough, as we learned from Phillip&amp;rsquo;s &lt;a href="https://blog.spiceai.org/posts/2021/12/05/ai-needs-ai-ready-data/">AI needs AI-ready data&lt;/a> post, all three data classes need to be in a format that ML can use.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px; margin-bottom: 20px;">
&lt;div style="display: grid;">
&lt;img style="max-width: 600px; margin: auto" alt="Traditional app and data integration." src="https://user-images.githubusercontent.com/80174/147722263-26333f5e-2da0-4c8c-a042-0c88c37d59be.png">
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Figure 2. Traditional app and data integration.&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>If you can afford a data or ML team, they may do much of this for you. However, this model starts to look quite waterfall-like and is not suited well to applications that want to learn and adapt in real-time. Like a waterfall approach, you would provide requirements to your data team, and they would do the data engineering required to provide you with the first two classes of data, historical and real-time. They may give you ML-ready data or train an ML model for you. However, there is often a large latency to apply that data or model in your application and a long turn-around time if it does not meet your requirements. In addition, to capture the third class of data, you would need to capture and send the results of the decisions your application made as a result of using those models back to the data team to incorporate in future learning. This latency through the data, decision-making, learning, and adaptation process is often infeasible for a real-world app.&lt;/p>
&lt;p>And, if you can&amp;rsquo;t afford a data team, you have to figure out how to do all that yourself.&lt;/p>
&lt;h3 id="the-agile-approach">The agile approach&lt;/h3>
&lt;p>Modern software engineering practices have favored agile methodologies to reduce time to learn and adapt applications to customer and business needs. Spice.ai takes inspiration from agile methods to provide developers with a fast, iterative development cycle.&lt;/p>
&lt;p>Spice.ai provides mechanisms for making all three classes of data available to both the application and the decision engine. Developers author Spicepods declaring how data should be captured, consumed, and made ML-ready so that all three classes are consistent and ML available.&lt;/p>
&lt;p>The Spice.ai runtime exposes developer-friendly APIs and data connectors for capturing and consuming data and annotating that data with personal context. The runtime generates AI-ready data for you and makes it available directly for ML. These APIs also make it easy to capture application decisions and incorporate the resulting learning.&lt;/p>
&lt;p>The Spice.ai approach short circuits the traditional waterfall-like data process by keeping as much data as possible application local instead of round-tripping through an external pipeline or team, especially valuable for real-time data. The application can learn and adapt faster by reducing the latency of decision consequences to learning.&lt;/p>
&lt;p>Spice.ai enables personalized learning from personal context and experiences through the interpretations mechanism. Interpretations allow an application to provide additional information or an &amp;ldquo;interpretation&amp;rdquo; of a time range as input to learning. The trading example could be as simple as labeling a time range as a good time to buy or providing additional contextual information such as tax considerations, etc. Developers can also use interpretations to record the results of decisions with more context than what might be available in the observation space. You can read more about Interpretations in the &lt;a href="https://docs.spiceai.org/concepts/interpretations/">Spice.ai docs&lt;/a>.&lt;/p>
&lt;p>While Spice.ai focuses on ensuring consistent ML-ready data is available, it does not replace traditional data systems or teams. They still have their place, especially for large historical datasets, and Spice.ai can consume data produced by them. Where possible, especially for application and real-time data, Spice.ai keeps runtime data local to create a virtuous cycle of data from the application to the decision engine and back again, enabling faster and more agile learning and adaption.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px; margin-bottom: 20px;">
&lt;div style="display: grid;">
&lt;img style="max-width: 600px; margin: auto" alt="App with Spice.ai." src="https://user-images.githubusercontent.com/80174/147721797-707d29b2-f93e-42be-809a-921349049895.png">
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Figure 3. App with Spice.ai.&lt;/div>
&lt;/div>
&lt;/div>
&lt;h3 id="summary">Summary&lt;/h3>
&lt;p>In summary, to build an intelligent application driven from AI recommended decisions, a significant amount of data engineering can be required to learn, make decisions, and incorporate the results. The Spice.ai runtime enables you as a developer to focus on consuming those decisions and tuning how the AI engine should learn rather than the runtime data engineering.&lt;/p>
&lt;p>The potential of the next generation of intelligent applications to improve the quality of our lives is very exciting. Using AI to help applications make better decisions, whether that be AI-assisted investing, improving the energy efficiency of our homes and buildings, or supporting us in deciding on the most appropriate medical treatment, is very promising.&lt;/p>
&lt;h3 id="learn-more-and-contribute">Learn more and contribute&lt;/h3>
&lt;p>Even for advanced developers, building intelligent apps that leverage AI is still way too hard. Our mission is to make this as easy as creating a modern web page. If that vision resonates with you, join us!&lt;/p>
&lt;p>If you want to get involved, we&amp;rsquo;d love to talk. Try out &lt;a href="https://spiceai.org">Spice.ai&lt;/a>, &lt;a href="mailto:hey@spiceai.io">email us&lt;/a> &amp;ldquo;hey,&amp;rdquo; get in touch on &lt;a href="https://discord.gg/kZnTfneP5u">Discord&lt;/a>, or reach out on &lt;a href="https://twitter.com/SpiceAIHQ">Twitter&lt;/a>.&lt;/p>
&lt;p>Luke&lt;/p></description></item><item><title>Posts: A New Class of Applications That Learn and Adapt</title><link>/posts/2021/12/30/a-new-class-of-applications-that-learn-and-adapt/</link><pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate><guid>/posts/2021/12/30/a-new-class-of-applications-that-learn-and-adapt/</guid><description>
&lt;p>A new class of applications that learn and adapt is becoming possible through machine learning (ML). These applications learn from data and make decisions to achieve the application&amp;rsquo;s goals. In the post &lt;a href="https://blog.spiceai.org/posts/2021/11/05/making-apps-that-learn-and-adapt/">Making apps that learn and adapt&lt;/a>, Luke described how developers integrate this ability to learn and adapt as a core part of the application&amp;rsquo;s logic. You can think of the component that does this as a &amp;ldquo;decision engine.&amp;rdquo; This post will explore a brief history of decision engines and use-cases for this application class.&lt;/p>
&lt;h2 id="history-of-decision-engines">History of decision engines&lt;/h2>
&lt;p>The idea to make intelligent decision-making applications is not new. Developers first created these applications around the 1970s&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>, and they are some of the earliest examples of using artificial intelligence to solve real-world problems.&lt;/p>
&lt;p>The first applications used a class of decision engines called &amp;ldquo;&lt;a href="https://en.wikipedia.org/wiki/Expert_system">expert systems&lt;/a>.&amp;rdquo; A distinguishing trait of expert systems is that they encode human expertise in rules for decision-making. Domain experts created combinations of rules that powered decision-making capabilities.&lt;/p>
&lt;p>Some uses of expert systems include:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://ieeexplore.ieee.org/document/9549566">Fault diagnosis&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.gregstanleyandassociates.com/whitepapers/IFAC91objectPaper.pdf">&amp;ldquo;Smart&amp;rdquo; operator and troubleshooting manual&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.gregstanleyandassociates.com/whitepapers/IFAC91objectPaper.pdf">Recovery from extreme conditions&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.gregstanleyandassociates.com/whitepapers/IFAC91objectPaper.pdf">Emergency shutdown&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>However, the resources required to build expert systems make employing them infeasible for many applications&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>. They often need a significant time and resource investment to capture and encode expertise into complex rule sets. These systems also do not automatically learn from experience, relying on experts to write more rules to improve decision-making.&lt;/p>
&lt;p>With the advent of modern deep-learning techniques and the ability to access significantly more data, it is now possible for the computer, not only the developer, to learn and encode the rules to power a decision engine and improve them over time. The vision for Spice.ai is to make it easy for developers to build this new class of applications. So what are some use-cases for these applications?&lt;/p>
&lt;h2 id="use-cases-of-decision-making-applications">Use cases of decision-making applications&lt;/h2>
&lt;h3 id="reduce-energy-costs-by-optimizing-air-conditioning">Reduce energy costs by optimizing air conditioning&lt;/h3>
&lt;p>&lt;strong>Today&lt;/strong>: The air conditioning system for an office building runs on a fixed schedule and is set to a fixed temperature in business hours, only adjusting using in-room sensor data, if at all. This behavior potentially over cools at business close as the outside temperature lowers and the building starts vacating.&lt;/p>
&lt;p>&lt;strong>With Spice.ai&lt;/strong>: Using Spice.ai, the application combines time-series data from multiple data sources, including the time of day and day of the week, building/room occupancy, and outside temperature, energy consumption, and pricing. The A/C controller application learns how to adjust the air conditioning system as the room naturally cools towards the end of the day. As the occupancy decreases, the decision engine is rewarded for maintaining the desired temperature and minimizing energy consumption/cost.&lt;/p>
&lt;h3 id="food-delivery-order-dispatching">Food delivery order dispatching&lt;/h3>
&lt;p>&lt;strong>Today:&lt;/strong> Customers order food delivery with a mobile app. When the order is ready to be picked up from the restaurant, the order is dispatched to a delivery driver by a simple heuristic that chooses the nearest available driver. As the app gets more popular with customers and the number of restaurants, drivers, and customers increases, the heuristic needs to be constantly tuned or supplemented with human operators to handle the demand.&lt;/p>
&lt;p>&lt;strong>With Spice.ai&lt;/strong>: The application learns which driver to dispatch to minimize delivery time and maximize customer star ratings. It considers several factors from data, including patterns in both the restaurant and driver&amp;rsquo;s order histories. As the number of users, drivers, and customers increases over time, the app adapts to keep up with the changing patterns and demands of the business.&lt;/p>
&lt;h3 id="routing-stock-or-crypto-trades-to-the-best-exchange">Routing stock or crypto trades to the best exchange&lt;/h3>
&lt;p>&lt;strong>Today:&lt;/strong> When trading stocks through a broker like Fidelity or TD Ameritrade, your broker will likely route your order to an exchange like the NYSE. And in the emerging world of crypto, you can place your trade or swap directly on a decentralized exchange (DEX) like &lt;a href="https://uniswap.org">Uniswap&lt;/a> or &lt;a href="https://pancakeswap.finance/">Pancake Swap&lt;/a>. In both cases, the routing of orders is likely to be either a form of traditional expert system based upon rules or even manually routed.&lt;/p>
&lt;p>&lt;strong>With Spice.ai:&lt;/strong> A smart order routing application learns from data such as pending transactions, time of day, day of the week, transaction size, and the recent history of transactions. It finds patterns to determine the most optimal route or exchange to execute the transaction and get you the best trade.&lt;/p>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;p>A new class of applications that can learn and adapt are made possible by integrating AI-powered decision engines. Spice.ai is a decision engine that makes it easy for developers to build these applications.&lt;/p>
&lt;p>If you&amp;rsquo;d like to partner with us in creating this new generation of intelligent decision-making applications, we invite you to join us on &lt;a href="https://discord.gg/kZnTfneP5u">Discord&lt;/a>, reach out on &lt;a href="https://twitter.com/SpiceAIHQ">Twitter&lt;/a> or &lt;a href="mailto:hey@spiceai.io">email&lt;/a> us.&lt;/p>
&lt;p>Phillip&lt;/p>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>Russell, Stuart; Norvig, Peter (1995). &lt;a href="http://aima.cs.berkeley.edu/">Artificial Intelligence: A Modern Approach&lt;/a>. Simon &amp;amp; Schuster. pp. 22â€“23. ISBN 978-0-13-103805-9.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>Kendal, S. L., &amp;amp; Creen, M. (2007). &lt;a href="https://www.worldcat.org/title/introduction-to-knowledge-engineering/oclc/70987401">An introduction to knowledge engineering&lt;/a>. London: Springer. ISBN 978-1-84628-475-5&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description></item><item><title>Posts: Announcing the release of Spice.ai v0.5.1-alpha</title><link>/posts/2021/12/28/announcing-the-release-of-spice.ai-v0.5.1-alpha/</link><pubDate>Tue, 28 Dec 2021 00:00:00 +0000</pubDate><guid>/posts/2021/12/28/announcing-the-release-of-spice.ai-v0.5.1-alpha/</guid><description>
&lt;p>Announcing the release of Spice.ai v0.5.1-alpha! ðŸ“ˆ&lt;/p>
&lt;p>This minor release builds upon v0.5-alpha adding the ability to start training from the dashboard plus support for monitoring training runs with &lt;a href="https://www.tensorflow.org/tensorboard/">TensorBoard&lt;/a>.&lt;/p>
&lt;h2 id="highlights-in-v051-alpha">Highlights in v0.5.1-alpha&lt;/h2>
&lt;h3 id="start-training-from-dashboard">Start training from dashboard&lt;/h3>
&lt;p>A &amp;ldquo;Start Training&amp;rdquo; button has been added to the pod page on the dashboard so that you can easily start training runs from that context.&lt;/p>
&lt;p>Training runs can now be started by:&lt;/p>
&lt;ul>
&lt;li>Modifications to the Spicepod YAML file.&lt;/li>
&lt;li>The &lt;a href="https://docs.spiceai.org/cli/reference/#train">spice train &lt;pod name>&lt;/a> command.&lt;/li>
&lt;li>The &amp;ldquo;Start Training&amp;rdquo; dashboard button.&lt;/li>
&lt;li>POST &lt;a href="https://docs.spiceai.org/api/">API calls&lt;/a> to &lt;code>/api/v0.1/pods/{pod name}/train&lt;/code>&lt;/li>
&lt;/ul>
&lt;div style="display: grid; justify-content: center; margin: 50px;">
&lt;video controls width="800" src="https://user-images.githubusercontent.com/80174/146122241-f8073266-ead6-4628-8563-93e98d74e9f0.mov">&lt;/video>
&lt;/div>
&lt;h3 id="tensorboard-monitoring">TensorBoard monitoring&lt;/h3>
&lt;p>&lt;a href="https://www.tensorflow.org/tensorboard/">TensorBoard&lt;/a> monitoring is now supported when using DQL (default) or the new SACD &lt;a href="https://docs.spiceai.org/deep-learning-ai/">learning algorithms&lt;/a> that was &lt;a href="https://github.com/spiceai/spiceai/releases/tag/v0.5-alpha">announced in v0.5-alpha&lt;/a>.&lt;/p>
&lt;p>When enabled, TensorBoard logs will automatically be collected and a &amp;ldquo;Open TensorBoard&amp;rdquo; button will be shown on the pod page in the dashboard.&lt;/p>
&lt;p>Logging can be enabled at the pod level with the &lt;a href="https://docs.spiceai.org/reference/pod/#paramstraining_loggers">training_loggers pod param&lt;/a> or per training run with the CLI &lt;code>--training-loggers&lt;/code> argument.&lt;/p>
&lt;div style="display: grid; justify-content: center; margin: 50px;">
&lt;video controls width="800" src="https://user-images.githubusercontent.com/80174/146382503-2bb2570b-5111-4de0-9b80-a1dc4a5dcc35.mov">&lt;/video>
&lt;/div>
&lt;p>Support for VPG will be added in v0.6-alpha. The design allows for additional loggers to be added in the future. Let us know what you&amp;rsquo;d like to see!&lt;/p>
&lt;h2 id="new-in-this-release">New in this release&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Adds&lt;/strong> a start training button on the dashboard pod page.&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> TensorBoard logging and monitoring when using DQL and SACD learning algorithms.&lt;/li>
&lt;/ul>
&lt;h3 id="dependency-updates">Dependency updates&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>Updates&lt;/strong> to Tailwind 3.0.6&lt;/li>
&lt;li>&lt;strong>Updates&lt;/strong> to Glide Data Grid 3.2.1&lt;/li>
&lt;/ul>
&lt;h2 id="resources">Resources&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://docs.spiceai.org/getting-started/">Getting started with Spice.ai&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.spiceai.org/">Documentation&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/spiceai/quickstarts/blob/trunk/README.md">Quickstarts&lt;/a> and &lt;a href="https://github.com/spiceai/samples/blob/trunk/README.md">Samples&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="community">Community&lt;/h2>
&lt;p>Spice.ai started with the vision to make AI easy for developers. We are building Spice.ai in the open and with the community. Reach out on Discord or by email to get involved. We will also be starting a community call series soon!&lt;/p>
&lt;ul>
&lt;li>Discord: &lt;a href="https://discord.gg/kZnTfneP5u">https://discord.gg/kZnTfneP5u&lt;/a>&lt;/li>
&lt;li>Reddit: &lt;a href="https://www.reddit.com/r/spiceai">https://www.reddit.com/r/spiceai&lt;/a>&lt;/li>
&lt;li>Twitter: &lt;a href="https://twitter.com/spiceaihq">@SpiceAIHQ&lt;/a>&lt;/li>
&lt;li>Email: &lt;a href="mailto:hey@spiceai.io">hey@spiceai.io&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Posts: Understanding Q-learning: How a Reward Is All You Need</title><link>/posts/2021/12/15/understanding-q-learning-how-a-reward-is-all-you-need/</link><pubDate>Wed, 15 Dec 2021 00:00:00 +0000</pubDate><guid>/posts/2021/12/15/understanding-q-learning-how-a-reward-is-all-you-need/</guid><description>
&lt;p>There are two general ways to train an AI to match a given expectation: we can either give it the expected outputs (commonly named labels) for differents inputs; we call this supervised learning. Or we can provide a reward for each output as a score: this is reinforcement learning (RL).&lt;/p>
&lt;p>Supervised learning works by tweaking all the parameters (weights in neural networks) to fit the desired outputs, expecting that given enough input/label pairs the AI will find common rules that generalize for any input.&lt;/p>
&lt;p>Reinforcement learning&amp;rsquo;s reward is often provided from a simple function that can score any output: we don&amp;rsquo;t know what specific output would be best, but we can recognize how good the result is. In this latter statement there are two underlying concepts we will address in this post:&lt;/p>
&lt;ul>
&lt;li>Can we only tell if the output is good in a binary way, or do we have to quantify the output to train our AI?&lt;/li>
&lt;li>Do we have to give a reward for every AI&amp;rsquo;s output? Can we give a reward only at specific times?&lt;/li>
&lt;/ul>
&lt;p>Those questions are already mostly answered, and many algorithms deal with those topics. Our journey here will be to understand how we tackle those questions and end up with a beautiful formula that is at the core of modern approaches of RL:&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px; min-height: 100px; margin: auto" src="/svg/q_learning/q_formula.svg" />
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Equation 1. Q estimation at the heart of many RL algorithm, also known as the Bellman equation.&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="q-learning">Q-learning&lt;/h2>
&lt;p>The vast majority, if not all, of modern RL algorithms are based on the principles of Q-learning: the idea is to evaluate a &amp;lsquo;reward expectation&amp;rsquo; for each possible action. If we can have a good evaluation, we could maximize the reward by choosing actions with the maximum evaluated rewards. The function giving this expected reward is named Q. For now, we will assume we can have a reward for any action.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px; min-height: 100px; margin: auto" src="/svg/q_learning/q_function.svg" />
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Equation 2. Definition of the Q function.&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>The &lt;code>t&lt;/code> indices show that the state and action aren&amp;rsquo;t constant and will vary, usually with time/action taken. On the other hand, the &lt;code>Q&lt;/code> function and the reward function &lt;code>r&lt;/code> are unique functions that ideally return the &amp;lsquo;expected reward&amp;rsquo; for any (state, action) pairs.&lt;/p>
&lt;p>For now, we will assume we can have a reward that gives an objective and perfect evaluation of each state/action.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px; margin: auto" src="https://user-images.githubusercontent.com/19952490/145569847-4be91c13-3ffb-4ad8-83c4-fb841e9d2c96.png" />
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Figure 1. Example of reward given for different actions at a specific state. Here a simple 2D map with a goal.&lt;/div>
&lt;/div>
&lt;/div>
&lt;h3 id="q-table">Q-Table&lt;/h3>
&lt;p>We know that actions' outcomes (rewards) will vary depending on the current state we are in, otherwise the problem would be trivial to solve. If the states that are relevant to our actions can be numbered, a simple way would be to build a table with all the possible states/action pairs. There are different ways to build such a table depending on how we can interact with our environment. Eventually, we would have a good &amp;lsquo;map&amp;rsquo; to guide us to do the best actions.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px; margin: auto" src="https://user-images.githubusercontent.com/19952490/145569842-298103e3-e7ed-412f-8229-66c745d29807.png" />
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Figure 2. Example of Q-table: we can build an exhaustive table for all the possible (state, action) pairs&lt;/div>
&lt;/div>
&lt;/div>
&lt;h3 id="deep-q-learning">Deep Q-Learning&lt;/h3>
&lt;p>When the number of variables of the environment relevant to our actions/rewards becomes too large, the number of possible states grows quickly. It doesn&amp;rsquo;t take a lot of possible parameters to make the Q-table approach unfeasible. Neural networks are known to work very nicely and efficiently in high dimensionality (with many input variables). They also generalize well, so the idea in Deep Q-Learning is to use a neural network to predict the different Q values for each action given a state.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px; margin: auto" src="https://user-images.githubusercontent.com/19952490/145569840-369d4eb0-48c6-44d8-bc5e-bfabdd7713a4.png" />
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Figure 3. A neural network can predict Q values from state information&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>In this case, we do not need to give the state/action pairs but only the state, as the neural network would exhaustively return all the Q values associated with each action. Outputting all actions' Q value is a common method as the general cases have a complex environment but a smaller number of possible actions.&lt;/p>
&lt;p>This method works very well. It is similar to supervised learning with states as inputs and rewards as labels. We assumed so far that we had a reward for each action, and we chose the next action with the best reward (called a greedy policy). In many cases this is not enough: even if an action would yield the best reward at a given state, this may affect the next state so that we wouldn&amp;rsquo;t optimize the reward in the long term. Also, if we can&amp;rsquo;t have a reward for each action, we usually give 0 as a reward. We will not be able to choose the right action if they affect later states despite not yielding different rewards at the current state.&lt;/p>
&lt;p>The sparsity of rewards or the long-term calculation of total reward (non-greedy policies) leads us to diverge from supervised learning and learn potential future rewards.&lt;/p>
&lt;h2 id="temporal-difference-td-learning">Temporal difference: TD-Learning&lt;/h2>
&lt;p>TD-learning is a clever way to account for potential future value without knowing them yet. TD is a model-free class of algorithms: it does not simulate future states. The main idea is to consider all the rewards of a sequence of actions to give a better value than just the reward of the next action.&lt;/p>
&lt;p>We can, for instance, sum all the future rewards:&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px; margin: auto" src="https://user-images.githubusercontent.com/19952490/145569849-f528b7df-a240-41d6-b850-fde58334cac5.png" />
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Figure 4. Cumulating future rewards to assign values to each state.&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>Mathematically this can be written as:&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px; min-height: 100px; margin: auto" src="/svg/q_learning/value_naive_function.svg" />
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Equation 3.&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>This is named TD(0): the simplest form of TD method, accumulating all the rewards.&lt;/p>
&lt;h3 id="introducing-policies">Introducing policies&lt;/h3>
&lt;p>We could try different trajectories (sequence of actions) and retrospectively get the final reward for each action, but this has 2 drawbacks: the environment is usually too vast, and the sequence of actions might not even have a definite end. Also, such exhaustive methods might not be very efficient. Instead, we can evaluate the &amp;lsquo;value&amp;rsquo; of the next state overall, like the maximum of all its possible rewards (direct reward), and add this value to the reward of a given action.&lt;/p>
&lt;p>If a state can have different branches, we can select the best one, and this would be our policy, the way we choose actions. This simple form of taking the maximum is called the &amp;lsquo;greedy&amp;rsquo; policy.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px; margin: auto" src="https://user-images.githubusercontent.com/19952490/145569828-f9505a88-1556-4c88-ba43-834daa60e594.png" />
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Figure 5. With a greedy policy the associated values to state come from the maximum value of the next state. Here despite the lower branch giving only half the top reward directly the overall value is greater.&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>This can be written down as:&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px; min-height: 100px; margin: auto" src="/svg/q_learning/value_policy_function.svg" />
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Equation 4.&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>The expected value notation is defined as:&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px; min-height: 100px; margin: auto" src="/svg/q_learning/expected_value.svg" />
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Equation 5.&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>For a greedy policy the probabilities &lt;code>p&lt;/code> would all be set to 0 but the one associated with the highest return to 1 (in case of equality between n actions, we would attribute &amp;lsquo;1/n&amp;rsquo; as probabilities to get the same expected value).&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px; min-height: 100px; margin: auto" src="/svg/q_learning/expected_greedy_value.svg" />
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Equation 6.&lt;/div>
&lt;/div>
&lt;/div>
&lt;h3 id="relation-with-q-function">Relation with Q function&lt;/h3>
&lt;p>The expected reward can be replaced by the Q function we used earlier, which now can be denominated to be specific to our chosen policy (named Ï€):&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px; min-height: 100px; margin: auto" src="/svg/q_learning/value_q_relation.svg" />
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Equation 7.&lt;/div>
&lt;/div>
&lt;/div>
&lt;h3 id="td-0">TD-0&lt;/h3>
&lt;p>We previously discussed the problem of not being able to go through all the states exhaustively and that the evaluation of the Q value from a neural network could help. We want to use the TD method to have a better value estimation that will consider potential future rewards.&lt;/p>
&lt;p>The TD(0) method is elegant as we can, in fact, only use the next state&amp;rsquo;s expected value instead of all future ones. The idea is that with successive evaluations, we build a chain of dependencies as each states' value depends on the next one.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px; min-height: 100px; margin: auto" src="/svg/q_learning/td_0_value.svg" />
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Equation 8.&lt;/div>
&lt;/div>
&lt;/div>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px; margin: auto" src="https://user-images.githubusercontent.com/19952490/145569853-335f65d9-aa16-44c6-9e97-287db5862628.png" />
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Figure 6. Iterative propagation of state values following TD(0) method.&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>We can see that the greedy policy would work even with null rewards in the trajectory. We can explicit our greedy policy, going back to use Q value instead of the state value V:&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px; min-height: 100px; margin: auto" src="/svg/q_learning/td_0_q.svg" />
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Equation 9.&lt;/div>
&lt;/div>
&lt;/div>
&lt;h3 id="td-lambda">TD-lambda&lt;/h3>
&lt;p>We need to fix a problem: if a trajectory grows too long or never ends, a state value can potentially grow indefinitely. To counter that, we can add a &lt;strong>discount factor&lt;/strong> (originally named lambda, usually refer as gamma in Q-learning) for the next state&amp;rsquo;s value:&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px; min-height: 100px; margin: auto" src="/svg/q_learning/td_lambda_q.svg" />
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Equation 10.&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>Notice that we simplify the reward notation for clarity.&lt;/p>
&lt;p>To avoid exploding values, this discount has to be between 0 and 1 (strictly below 1). We can think about it as giving more importance to the direct reward than the future ones. As the contribution to the latter reward decrease, the chain of action can grow without the calculated value growing. If the reward has an upper limit, the value will also be bounded.&lt;/p>
&lt;p>The sparsity of rewards is also solved: giving only a positive reward after many non-rewarding steps will create smooth values for the intermediate states. Any reward, positive or negative, will diffuse its value to the neighbor states.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px; margin: auto" src="https://user-images.githubusercontent.com/19952490/145569835-ff21b42f-21d0-4eb3-a451-9b9aa5a76f78.png" />
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Figure 7. The TD(0) value propagation can allow for a smooth value distribution over the state that will help building efficient behaviour.&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="q-learning-algorithm">Q-Learning algorithm&lt;/h2>
&lt;p>Finally, as we train a neural network to estimate the Q function, we need to update its target with successive iteration. We cannot fully trust the estimator (a neural network here) to give the correct value, so we introduce a learning rate to update the target smoothly.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 800px; min-height: 160px; margin: auto" src="/svg/q_learning/final_formula.svg" />
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Equation 11. Fully explained Bellman equation.&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>That is it! We now understand all the parts of this formula. Over multiple training steps with different sates, the training should find a good average Q function. While training, the estimator uses its own output to train itself (commonly referred to as bootstrapping): it is like it is chasing itself. Bootstrapping can lead to instability in the training process. There are many additional methods to help against such instability.&lt;/p>
&lt;p>From giving rewards, sparse or not, binary or fine-grained, we have a smooth space of values for all our states/actions so the AI can follow a greedy policy to the best outcome.&lt;/p>
&lt;p>This way of training is not a silver bullet and there is no guarantee that the AI will find a correlation from the information given as state to the returned reward.&lt;/p>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>We can see how our rewards are used to train AI&amp;rsquo;s policies using Q-learning. By understanding the many iterations required and the bootstrapping issues, we can help our AI by carefully giving relevant state information and reward:&lt;/p>
&lt;ul>
&lt;li>There needs to be a correlation between the state information and the reward: the simpler the relationship, the easier/faster the AI will find it.&lt;/li>
&lt;li>Sparse and binary rewards make the training problem long and arduous. Giving more information through the reward can tremendously increase the speed/accuracy of the learned Q-estimator.&lt;/li>
&lt;li>The longer the chain of actions, the more complex the Q-value will be to estimate.&lt;/li>
&lt;/ul>
&lt;p>We didn&amp;rsquo;t see how the AI&amp;rsquo;s algorithm can explore different actions given an environment here. Spice.ai&amp;rsquo;s technology focuses exclusively on off-policy training where we only have past data and cannot interact with the environment. RL is a vast topic and currently quickly growing. Robotics is a fantastic field of application; many other areas are yet to be explored with such a technology. We hope to push forward the technology and its field of application with our platform.&lt;/p>
&lt;p>If you&amp;rsquo;d like to partner with us on the mission of making new applications by leveraging RL, we invite you to discuss with us on &lt;a href="https://discord.gg/kZnTfneP5u">Discord&lt;/a>, reach out on &lt;a href="https://twitter.com/SpiceAIHQ">Twitter&lt;/a> or &lt;a href="mailto:hey@spiceai.io">email us&lt;/a>.&lt;/p>
&lt;p>I hope you enjoy this post and learn new things.&lt;/p>
&lt;p>Corentin&lt;/p></description></item><item><title>Posts: Announcing the release of Spice.ai v0.5-alpha</title><link>/posts/2021/12/06/announcing-the-release-of-spice.ai-v0.5-alpha/</link><pubDate>Mon, 06 Dec 2021 00:00:00 +0000</pubDate><guid>/posts/2021/12/06/announcing-the-release-of-spice.ai-v0.5-alpha/</guid><description>
&lt;p>We are excited to announce the release of Spice.ai v0.5-alpha! ðŸ¥‡&lt;/p>
&lt;p>Highlights include a new learning algorithm called &amp;ldquo;Soft Actor-Critic&amp;rdquo; (SAC), fixes to the behavior of &lt;code>spice upgrade&lt;/code>, and a more consistent authoring experience for reward functions.&lt;/p>
&lt;p>If you are new to Spice.ai, check out the &lt;a href="https://docs.spiceai.org/getting-started/">getting started guide&lt;/a> and star &lt;a href="https://github.com/spiceai/spiceai">spiceai/spiceai&lt;/a> on GitHub.&lt;/p>
&lt;h2 id="highlights-in-v05-alpha">Highlights in v0.5-alpha&lt;/h2>
&lt;h3 id="soft-actor-critic-discrete-sac-learning-algorithm">Soft Actor-Critic (Discrete) (SAC) Learning Algorithm&lt;/h3>
&lt;p>The addition of the Soft Actor-Critic (Discrete) (SAC) learning algorithm is a significant improvement to the power of the AI engine. It is not set as the default algorithm yet, so to start using it pass the &lt;code>--learning-algorithm sacd&lt;/code> parameter to &lt;code>spice train&lt;/code>. We&amp;rsquo;d love to get your feedback on how its working!&lt;/p>
&lt;h3 id="consistent-reward-authoring-experience">Consistent reward authoring experience&lt;/h3>
&lt;p>With the addition of the reward function files that allow you to edit your reward function in a Python file, the behavior of starting a new training session by editing the reward function code was lost. With this release, that behavior is restored.&lt;/p>
&lt;p>In addition, there is a breaking change to the variables used to access the observation state and interpretations. This change was made to better reflect the purpose of the variables and make them easier to work with in Python&lt;/p>
&lt;div class="table-wide" style="display: grid; justify-content: center; margin: 50px;">
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Previous (Type)&lt;/th>
&lt;th>New (Type)&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>prev_state&lt;/code> (SimpleNamespace)&lt;/td>
&lt;td>&lt;code>current_state&lt;/code> (dict)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>prev_state.interpretations&lt;/code> (list)&lt;/td>
&lt;td>&lt;code>current_state_interpretations&lt;/code> (list)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>new_state&lt;/code> (SimpleNamespace)&lt;/td>
&lt;td>&lt;code>next_state&lt;/code> (dict)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>new_state.interpretations&lt;/code> (list)&lt;/td>
&lt;td>&lt;code>next_state_interpretations&lt;/code> (list)&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/div>
&lt;h3 id="improved-spice-upgrade-behavior">Improved spice upgrade behavior&lt;/h3>
&lt;p>The Spice.ai CLI will no longer recommend &amp;ldquo;upgrading&amp;rdquo; to an older version. An issue was also fixed where trying to upgrade the Spice.ai CLI using &lt;code>spice upgrade&lt;/code> on Linux would return an error.&lt;/p>
&lt;h2 id="new-in-this-release">New in this release&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Adds&lt;/strong> a new learning algorithm called &amp;ldquo;Soft-Actor Critic&amp;rdquo; (SAC).&lt;/li>
&lt;li>&lt;strong>Updates&lt;/strong> the reward function parameters for the YAML code blocks from &lt;code>prev_state&lt;/code> and &lt;code>new_state&lt;/code> to &lt;code>current_state&lt;/code> and &lt;code>next_state&lt;/code> to be consistent with the reward function files.&lt;/li>
&lt;li>&lt;strong>Fixes&lt;/strong> an issue where editing a reward functions file would not automatically trigger training.&lt;/li>
&lt;li>&lt;strong>Fixes&lt;/strong> the normalization of values for the Deep-Q Learning algorithm to handle larger values.&lt;/li>
&lt;li>&lt;strong>Fixes&lt;/strong> an issue where the Spice.ai CLI would not upgrade on Linux with the &lt;code>spice upgrade&lt;/code> command.&lt;/li>
&lt;li>&lt;strong>Fixes&lt;/strong> an issue where the Spice.ai CLI would recommend an &amp;ldquo;upgrade&amp;rdquo; to an older version.&lt;/li>
&lt;/ul>
&lt;h2 id="resources">Resources&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://docs.spiceai.org/getting-started/">Getting started with Spice.ai&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.spiceai.org/">Documentation&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/spiceai/quickstarts/blob/trunk/README.md">Quickstarts&lt;/a> and &lt;a href="https://github.com/spiceai/samples/blob/trunk/README.md">Samples&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="community">Community&lt;/h2>
&lt;p>Spice.ai started with the vision to make AI easy for developers. We are building Spice.ai in the open and with the community. Reach out on Discord or by email to get involved. We will also be starting a community call series soon!&lt;/p>
&lt;ul>
&lt;li>Discord: &lt;a href="https://discord.gg/kZnTfneP5u">https://discord.gg/kZnTfneP5u&lt;/a>&lt;/li>
&lt;li>Reddit: &lt;a href="https://www.reddit.com/r/spiceai">https://www.reddit.com/r/spiceai&lt;/a>&lt;/li>
&lt;li>Twitter: &lt;a href="https://twitter.com/spiceaihq">@SpiceAIHQ&lt;/a>&lt;/li>
&lt;li>Email: &lt;a href="mailto:hey@spiceai.io">hey@spiceai.io&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Posts: AI needs AI-ready data</title><link>/posts/2021/12/05/ai-needs-ai-ready-data/</link><pubDate>Sun, 05 Dec 2021 00:00:00 +0000</pubDate><guid>/posts/2021/12/05/ai-needs-ai-ready-data/</guid><description>
&lt;p>A significant challenge when developing an app powered by AI is providing the machine learning (ML) engine with data in a format that it can use to learn. To do that, you need to normalize the numerical data, one-hot encode categorical data, and decide what to do with incomplete data - among other things.&lt;/p>
&lt;p>This data handling is often challenging! For example, to learn from Bitcoin price data, the prices are better if normalized to a range between -1 and 1. Being close to 0 is also a problem because of the lack of precision in floating-point representations (usually under 1e-5).&lt;/p>
&lt;p>As a developer, if you are new to AI and machine learning, a great talk that explains the basics is &lt;a href="https://www.youtube.com/watch?v=VwVg9jCtqaU">Machine Learning Zero to Hero&lt;/a>. Spice.ai makes the process of getting the data into an AI-ready format easy by doing it for you!&lt;/p>
&lt;h2 id="what-is-ai-ready-data">What is AI-ready data?&lt;/h2>
&lt;p>You write code with if statements and functions, but your machine only understands 1s and 0s. When you write code, you leverage tools, like a compiler, to translate that human-readable code into a machine-readable format.&lt;/p>
&lt;p>Similarly, data for AI needs to be translated or &amp;ldquo;compiled&amp;rdquo; to be understood by the ML engine. You may have heard of &lt;a href="https://www.tensorflow.org/guide/tensor">tensors&lt;/a> before; they are simply another word for a multi-dimensional array and they are the language of ML engines. All inputs to and all outputs from the engine are in tensors. You could use the following techniques when converting (or &amp;ldquo;compiling&amp;rdquo;) source data to a tensor.&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Normalization/standardization of the numerical input data.&lt;/strong> Many of the inputs and outputs in machine learning are interpreted as probability distributions. Much of the math that powers machine learning, such as softmax, tanh, sigmoid, etc., is meant to work in the [-1, 1] range.&lt;/li>
&lt;/ol>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: grid;">
&lt;img style="max-width: 563px; margin: auto" alt="Normalizing raw data" src="https://user-images.githubusercontent.com/879445/144733722-46baa2f7-5e94-4113-9770-735987d6a390.png">
&lt;div style="font-size: 0.8rem; font-style: italic; text-align: center;">Figure 1. Normalizing Bitcoin price data.&lt;/div>
&lt;/div>
&lt;/div>
&lt;ol start="2">
&lt;li>&lt;strong>Conversion of categorical data into numerical data.&lt;/strong> For categorical data (i.e., colors such as &amp;ldquo;red,&amp;rdquo; &amp;ldquo;blue,&amp;rdquo; or &amp;ldquo;green&amp;rdquo;), you can achieve this through a technique called &lt;a href="https://www.educative.io/blog/one-hot-encoding">&amp;ldquo;One Hot Encoding.&amp;quot;&lt;/a> In one hot encoding, each possible value in the category appears as a column. The values in the column are assigned a binary value of 1 or 0 depending on whether the value exists or not.&lt;/li>
&lt;/ol>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 300px; margin: auto" src="https://user-images.githubusercontent.com/879445/144733213-bd162dc0-7ac9-4bbb-9115-1dc46d2084cf.png" />
&lt;div style="font-size: 0.8rem; font-style: italic;">Figure 2. A visualization of one-hot encoding&lt;/div>
&lt;/div>
&lt;/div>
&lt;ol start="3">
&lt;li>Several advanced techniques exist for &amp;ldquo;compiling&amp;rdquo; this source data - this process is known in the AI world as &amp;ldquo;feature engineering.&amp;rdquo; &lt;a href="https://developers.google.com/machine-learning/crash-course/representation/feature-engineering">This article&lt;/a> goes into more detail on feature engineering techniques if you are interested in learning more.&lt;/li>
&lt;/ol>
&lt;p>There are excellent tools like &lt;a href="https://pandas.pydata.org/">Pandas&lt;/a>, &lt;a href="https://numpy.org/">Numpy&lt;/a>, &lt;a href="https://scipy.org/">scipy&lt;/a>, and others that make the process of data transformation easier. However, most of these tools are Python libraries and frameworks - which means having to learn Python if you don&amp;rsquo;t know it already. Plus, when building intelligent apps (instead of just doing pure data analysis), this all needs to work on real-time data in production.&lt;/p>
&lt;h2 id="building-intelligent-apps">Building intelligent apps&lt;/h2>
&lt;p>The tools mentioned above are not designed for building real-time apps. They are often designed for analytics/data science.&lt;/p>
&lt;p>In your app, you will need to do this data compilation in real-time - and you can&amp;rsquo;t rely on a local script to help process your data.
It becomes trickier if the team responsible for the initial training of the machine learning model is not the team responsible for deploying it out into production.&lt;/p>
&lt;p>How data is loaded and processed in a static dataset is likely very different from how the data is loaded and processed in real-time as your app is live. The result often is two separate codebases that are maintained by different teams that are both responsible for doing the same thing! Ensuring that those codebases stay consistent and evolve together is another challenge to tackle.&lt;/p>
&lt;h2 id="spiceai-helps-developers-build-apps-with-real-time-ml">Spice.ai helps developers build apps with real-time ML&lt;/h2>
&lt;p>Spice.ai handles the &amp;ldquo;compilation&amp;rdquo; of data for you.&lt;/p>
&lt;p>You specify the data that your ML should learn from in a &lt;a href="https://blog.spiceai.org/posts/2021/12/02/spicepods-from-zero-to-hero/">Spicepod&lt;/a>. The Spice.ai runtime handles the logistics of gathering the data and compiling it into an AI-ready format.&lt;/p>
&lt;p>It does this by using many techniques described earlier, such as normalization and one-hot encoding. And because we&amp;rsquo;re continuing to evolve Spice.ai, our data compilation will only get better over time.&lt;/p>
&lt;p>In addition, the design of the Spice.ai runtime naturally ensures that the data used for both the training and real-time cases are consistent. Spice.ai uses the same data-components and runtime logic to produce the data. And not only that, you can take this a step further and share your Spicepod with someone else, and they would be able to use the same AI-ready data for their applications.&lt;/p>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;p>Spice.ai handles the process of compiling your data into an AI-ready format in a way that is consistent both during the training and real-time stages of the ML engine. A Spicepod defines which data to get and where to get it. Sharing this Spicepod allows someone else to use the same AI-ready data format in their application.&lt;/p>
&lt;h3 id="learn-more-and-contribute">Learn more and contribute&lt;/h3>
&lt;p>Building intelligent apps that leverage AI is still way too hard, even for advanced developers. Our mission is to make this as easy as creating a modern web page. If the vision resonates with you, join us!&lt;/p>
&lt;p>Our &lt;a href="https://github.com/spiceai/spiceai/blob/trunk/docs/ROADMAP.md">Spice.ai Roadmap&lt;/a> is public, and now that we have launched, the project and work are open for collaboration.&lt;/p>
&lt;p>If you are interested in partnering, we&amp;rsquo;d love to talk. Try out &lt;a href="https://spiceai.org">Spice.ai&lt;/a>, &lt;a href="mailto:hey@spiceai.io">email us&lt;/a> &amp;ldquo;hey,&amp;rdquo; get in touch on &lt;a href="https://discord.gg/kZnTfneP5u">Discord&lt;/a>, or reach out on &lt;a href="https://twitter.com/SpiceAIHQ">Twitter&lt;/a>.&lt;/p>
&lt;p>We are just getting started! ðŸš€&lt;/p>
&lt;p>Phillip&lt;/p></description></item><item><title>Posts: Spicepods: From Zero To Hero</title><link>/posts/2021/12/02/spicepods-from-zero-to-hero/</link><pubDate>Thu, 02 Dec 2021 00:00:00 +0000</pubDate><guid>/posts/2021/12/02/spicepods-from-zero-to-hero/</guid><description>
&lt;p>In my previous post, &lt;a href="https://blog.spiceai.org/posts/2021/11/15/teaching-apps-how-to-learn-with-spicepods/">Teaching Apps how to Learn with Spicepods&lt;/a>, I introduced Spicepods as packages of configuration that describe an application&amp;rsquo;s data-driven goals and how it should learn from data. To leverage Spice.ai in your application, you can author a Spicepod from scratch or build upon one fetched from the spicerack.org registry. In this post, we&amp;rsquo;ll walk through the creation and authoring of a Spicepod step-by-step from scratch.&lt;/p>
&lt;p>As a refresher, a Spicepod consists of:&lt;/p>
&lt;ul>
&lt;li>A required YAML manifest that describes how the pod should learn from data&lt;/li>
&lt;li>Optional seed data&lt;/li>
&lt;li>Learned model/state&lt;/li>
&lt;li>Performance telemetry and metrics&lt;/li>
&lt;/ul>
&lt;p>We&amp;rsquo;ll create the Spicepod for the &lt;a href="https://github.com/spiceai/quickstarts/tree/trunk/serverops/README.md">ServerOps Quickstart&lt;/a>, an application that learns when to optimally run server maintenance operations based upon the CPU-usage patterns of a server machine.&lt;/p>
&lt;p>We&amp;rsquo;ll also use the Spice CLI, which you can install by following the &lt;a href="https://docs.spiceai.org/getting-started/">Getting Started guide&lt;/a> or &lt;a href="https://www.youtube.com/watch?v=DKBLjuAz_lI">Getting Started YouTube video&lt;/a>.&lt;/p>
&lt;h2 id="fast-iterations">Fast iterations&lt;/h2>
&lt;p>Modern web development workflows often include a file watcher to hot-reload so you can iteratively see the effect of your change with a live preview.&lt;/p>
&lt;p>Spice.ai takes inspiration and enables a similar Spicepod manifest authoring experience. If you first start the Spice.ai runtime in your application root before creating your Spicepod, it will watch for changes and apply them continuously so that you can develop in a fast, iterative workflow.&lt;/p>
&lt;p>You would normally do this by opening two terminal windows side-by-side, one that runs the runtime using the command &lt;code>spice run&lt;/code> and one where you enter CLI commands. In addition, developers would open the Spice.ai dashboard located at &lt;a href="http://localhost:8000">http://localhost:8000&lt;/a> to preview changes they make.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px;" alt="Figure 1. Spice.ai's modern development workflow" src="https://user-images.githubusercontent.com/80174/144368808-1b1ce9dc-e296-42ff-a65d-44b8aa97605f.png">
&lt;/div>
&lt;/div>
&lt;h2 id="creating-a-spicepod">Creating a Spicepod&lt;/h2>
&lt;p>The easiest way to create a Spicepod is to use the Spice.ai CLI command: &lt;code>spice init &amp;lt;Spicepod name&amp;gt;&lt;/code>. We&amp;rsquo;ll make one in the ServerOps Quickstart application called &lt;code>serverops&lt;/code>.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px;" alt="Figure 2. Creating a Spicepod." src="https://user-images.githubusercontent.com/80174/144368947-2698d7e2-e451-4961-a289-d84f4f328eae.png">
&lt;/div>
&lt;/div>
&lt;p>The CLI saves the Spicepod manifest file in the &lt;code>spicepods&lt;/code> directory of your application. You can see it created a new serverops.yaml file, which should be included in your application and be committed to your source repository. Let&amp;rsquo;s take a look at it.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px;" alt="Figure 3. Spicepod manifest." src="https://user-images.githubusercontent.com/80174/144369087-59022f3d-84cc-4f8f-bceb-c60351ac69b7.png">
&lt;/div>
&lt;/div>
&lt;p>The initialized manifest file is very simple. It contains a name and three main sections being:&lt;/p>
&lt;ul>
&lt;li>dataspaces&lt;/li>
&lt;li>actions&lt;/li>
&lt;li>training&lt;/li>
&lt;/ul>
&lt;p>We&amp;rsquo;ll walk through each of these in detail, and as a Spicepod author, you can always reference the documentation for the &lt;a href="https://docs.spiceai.org/reference/pod/">Spicepod manifest syntax&lt;/a>.&lt;/p>
&lt;h2 id="authoring-a-spicepod-manifest">Authoring a Spicepod manifest&lt;/h2>
&lt;p>You author and edit Spicepod manifest files in your favorite text editor with a combination of Spice.ai CLI helper commands. We eventually plan to have a VS Code extension and dashboard/portal editing abilities to make this even easier.&lt;/p>
&lt;h2 id="adding-a-dataspace">Adding a dataspace&lt;/h2>
&lt;p>To build an intelligent, data-driven application, we must first start with data.&lt;/p>
&lt;p>A Spice.ai &lt;strong>dataspace&lt;/strong> is a logical grouping of data with definitions of how that data should be loaded and processed, usually from a single source. A combination of its data source and its name identifies it, for example, nasdaq/msft or twitter/tweets. Read more about Dataspaces in the &lt;a href="https://docs.spiceai.org/concepts/dataspaces/">Core Concepts&lt;/a> documentation.&lt;/p>
&lt;p>Let&amp;rsquo;s add a dataspace to the Spicepod manifest to load CPU metric data from a CSV file. This file is a snapshot of data from &lt;a href="https://www.influxdata.com/products/influxdb/">InfluxDB&lt;/a>, a time-series database we like.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px;" alt="Figure 4. Adding a dataspace." src="https://user-images.githubusercontent.com/80174/144369723-4336a4d5-1637-42c8-94aa-369531d6d1f7.png">
&lt;/div>
&lt;/div>
&lt;p>We can see this dataspace is identified by its source &lt;code>hostmetrics&lt;/code> and name &lt;code>cpu&lt;/code>. It includes a &lt;code>data&lt;/code> section with a file data connector, the path to the file, and a data processor to know how to process it. In addition, it defines a single measurement &lt;code>usage_idle&lt;/code> under the measurements section, which is a measurement of CPU load. In Spice.ai, measurements are the core primitive the AI engine uses to learn and is always numerical data. Spice.ai includes a growing library of community contributable data connectors and data processors you can consist of in your Spicepod to access data. You can also contribute your own.&lt;/p>
&lt;p>Finally, because the data is a snapshot of live data loaded from a file, we must set a Spicepod &lt;code>epoch_time&lt;/code> that defines the data&amp;rsquo;s start Unix time.&lt;/p>
&lt;p>Now we have a dataspace, called &lt;code>hostmetrics/cpu&lt;/code>, that loads CSV data from a file and processes the data into a &lt;code>usage_idle&lt;/code> measurement. The file connector might be swapped out with the InfluxDB connector in a production application to stream real-time CPU metrics into Spice.ai. And in addition, applications can always send real-time data to the Spice.ai runtime through its API with a simple HTTP POST (and in the future, using Web Sockets and gRPC).&lt;/p>
&lt;h2 id="adding-actions">Adding actions&lt;/h2>
&lt;p>Now that the Spicepod has data, let&amp;rsquo;s define some data-driven actions so the ServerOps application can learn when is the best time to take them. We&amp;rsquo;ll add three actions using the CLI helper command, &lt;code>spice action add&lt;/code>.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px;" alt="Figure 5. Adding actions." src="https://user-images.githubusercontent.com/80174/144369840-1dcea686-9661-408a-a8a4-c62e3d84093f.png">
&lt;/div>
&lt;/div>
&lt;p>And in the manifest:&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px;" alt="Figure 6. Actions added to the manifest" src="https://user-images.githubusercontent.com/80174/144371117-5eb816aa-e088-4160-8f33-9dabf1a5bb7c.png">
&lt;/div>
&lt;/div>
&lt;h2 id="adding-rewards">Adding rewards&lt;/h2>
&lt;p>The Spicepod now has data and possible actions, so we can now define how it should learn when to take them. Similar to how humans learn, we can set rewards or punishments for actions taken based on their effect and the data. Let&amp;rsquo;s add scaffold rewards for all actions using the &lt;code>spice rewards add&lt;/code> command.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px;" alt="Figure 7. Adding rewards" src="https://user-images.githubusercontent.com/80174/144371214-86803184-5100-45cb-a592-ac3114176dba.png">
&lt;/div>
&lt;/div>
&lt;p>We now have rewards set for each action. The rewards are uniform (all the same), meaning the Spicepod is rewarded the same for each action. Higher rewards are better, so if we change &lt;code>perform_maintenance&lt;/code> to 2, the Spicepod will learn to perform maintenance more often than the other actions. Of course, instead of setting these arbitrarily, we want to learn from data, and we can do that by referencing the state of data at each time-step in the time-series data as the AI engine trains.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px;" alt="Figure 8. Rewards added to the manifest" src="https://user-images.githubusercontent.com/80174/144371299-70b40d99-85e1-4ab8-b1e1-f4f40aa27fc7.png">
&lt;/div>
&lt;/div>
&lt;p>The rewards themselves are just code. Currently, we currently support Python code, either inline or in a .py &lt;a href="https://docs.spiceai.org/concepts/rewards/external/">external code file&lt;/a> and we plan to support several other languages. The reward code can access the time-step state through the &lt;code>prev_state&lt;/code> and &lt;code>new_state&lt;/code> variables and the dataspace name. For the full documentation, see &lt;a href="https://docs.spiceai.org/concepts/rewards/">Rewards&lt;/a>.&lt;/p>
&lt;p>Let&amp;rsquo;s add this reward code to perform_maintenance, which will reward performing maintenance when there is low CPU usage.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">&lt;span style="color:#000">cpu_usage_prev&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">100&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">-&lt;/span> &lt;span style="color:#000">prev_state&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">hostmetrics_cpu_usage_idle&lt;/span>
&lt;span style="color:#000">cpu_usage_new&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">100&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">-&lt;/span> &lt;span style="color:#000">new_state&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">hostmetrics_cpu_usage_idle&lt;/span>
&lt;span style="color:#000">cpu_usage_delta&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">cpu_usage_prev&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">-&lt;/span> &lt;span style="color:#000">cpu_usage_new&lt;/span>
&lt;span style="color:#000">reward&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">cpu_usage_delta&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">100&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This code takes the CPU usage (100 minus the idle time) deltas between the previous time state and the current time state, and sets the reward to be a normalized delta value between 0 and 1. When the CPU usage is moving from higher &lt;code>cpu_usage_prev&lt;/code> to lower &lt;code>cpu_usage_low&lt;/code>, its a better time to run server maintenance and so we reward the inverse of the delta. E.g. &lt;code>80% - 50% = 30% = 0.3&lt;/code>. However, if the CPU moves lower to higher, &lt;code>50% - 80% = -30% = -0.3&lt;/code>, it&amp;rsquo;s a bad time to run maintenance, so we provide a negative reward or &amp;ldquo;punish&amp;rdquo; the action.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px;" alt="Figure 9. Reward code" src="https://user-images.githubusercontent.com/80174/144371629-497f0ed4-1217-4e55-b7dd-0eec3eb187ae.png">
&lt;/div>
&lt;/div>
&lt;p>Through these rewards and punishments and the CPU metric data, the Spicepod will when it is a good time to perform maintence and be the decision engine for the ServerOps application. You might be thinking you could write code without AI to do this, which is true, but handling the variety of cases, like CPU spikes, or patterns in the data, like cyclical server load, would take a lot of code and a development time. Applying AI helps you build faster.&lt;/p>
&lt;h2 id="putting-it-all-together">Putting it all together&lt;/h2>
&lt;p>The manifest now has defined data, actions, and rewards. The Spicepod can get data to learn which actions to take and when based on the rewards provided.&lt;/p>
&lt;p>If the Spice.ai runtime is running, the Spicepod automatically trains each time the manifest file is saved. As this happens reward performance can be monitored in the dashboard.&lt;/p>
&lt;p>Once a training run completes, the application can query the Spicepod for a decision recommendation by calling the recommendations API http://localhost:8000/api/v0.1/pods/serverops/recommendation. The API returns a JSON document that provides the recommended action, the confidence of taking that action, and when that recommendation is valid.&lt;/p>
&lt;p>In the &lt;a href="https://github.com/spiceai/quickstarts/tree/trunk/serverops/README.md">ServerOps Quickstart&lt;/a>, this API is called from the server maintenance PowerShell script to make an intelligent decision on when to run maintenance. The &lt;a href="https://github.com/spiceai/samples/tree/trunk/serverops/README.md">ServerOps Sample&lt;/a>, which uses live data, can be continuously trained to learn and adapt even as the live data changes due to load patterns changing.&lt;/p>
&lt;p>The full Spicepod manifest from this walkthrough can be added from &lt;a href="https://spicerack.org">spicerack.org&lt;/a> using the &lt;code>spice add quickstarts/serverops&lt;/code> command.&lt;/p>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;p>Leveraging Spice.ai to be the decision engine for your server maintenance application helps you build smarter applications, faster that will continue to learn and adapt over time, even as usage patterns change over time.&lt;/p>
&lt;h3 id="learn-more-and-contribute">Learn more and contribute&lt;/h3>
&lt;p>Building intelligent apps that leverage AI is still way too hard, even for advanced developers. Our mission is to make this as easy as creating a modern web page. If the vision resonates with you, join us!&lt;/p>
&lt;p>Our &lt;a href="https://github.com/spiceai/spiceai/blob/trunk/docs/ROADMAP.md">Spice.ai Roadmap&lt;/a> is public, and now that we have launched, the project and work are open for collaboration.&lt;/p>
&lt;p>If you are interested in partnering, we&amp;rsquo;d love to talk. Try out &lt;a href="https://spiceai.org">Spice.ai&lt;/a>, &lt;a href="mailto:hey@spiceai.io">email us&lt;/a> &amp;ldquo;hey,&amp;rdquo; get in touch on &lt;a href="https://discord.gg/kZnTfneP5u">Discord&lt;/a>, or reach out on &lt;a href="https://twitter.com/SpiceAIHQ">Twitter&lt;/a>.&lt;/p>
&lt;p>We are just getting started! ðŸš€&lt;/p>
&lt;p>Luke&lt;/p></description></item><item><title>Posts: Announcing the release of Spice.ai v0.4.1-alpha</title><link>/posts/2021/11/22/announcing-the-release-of-spice.ai-v0.4.1-alpha/</link><pubDate>Mon, 22 Nov 2021 00:00:00 +0000</pubDate><guid>/posts/2021/11/22/announcing-the-release-of-spice.ai-v0.4.1-alpha/</guid><description>
&lt;p>Announcing the release of Spice.ai v0.4.1-alpha! âœ…&lt;/p>
&lt;p>This point release focuses on fixes and improvements to v0.4-alpha. Highlights include AI engine performance improvements, updates to the dashboard observations data grid, notification of new CLI versions, and several bug fixes.&lt;/p>
&lt;p>A special acknowledgment to &lt;a href="https://github.com/Adm28">@Adm28&lt;/a>, who added the CLI upgrade detection and prompt, which notifies users of new CLI versions and prompts to upgrade.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 400px;" src="https://user-images.githubusercontent.com/80174/142827883-c3791f8b-82dc-4e66-80d7-899268396f32.png" />
&lt;/div>
&lt;/div>
&lt;h2 id="highlights-in-v041-alpha">Highlights in v0.4.1-alpha&lt;/h2>
&lt;h3 id="ai-engine-performance-improvements">AI engine performance improvements&lt;/h3>
&lt;p>Overall training performance has been improved up to 13% by removing a lock in the AI engine.&lt;/p>
&lt;p>In versions before v0.4.1-alpha, performance was especially impacted when streaming new data during a training run.&lt;/p>
&lt;h3 id="dashboard-observations-datagrid">Dashboard Observations Datagrid&lt;/h3>
&lt;p>The dashboard observations datagrid now automatically resizes to the window width, and headers are easier to read, with automatic grouping into dataspaces. In addition, column widths are also resizable.&lt;/p>
&lt;h3 id="cli-version-detection-and-upgrade-prompt">CLI version detection and upgrade prompt&lt;/h3>
&lt;p>When it is run, the Spice.ai CLI will now automatically check for new CLI versions once a day maximum.&lt;/p>
&lt;p>If it detects a new version, it will print a notification to the console on &lt;code>spice version&lt;/code>, &lt;code>spice run&lt;/code> or &lt;code>spice add&lt;/code> commands prompting the user to upgrade using the new &lt;code>spice upgrade&lt;/code> command.&lt;/p>
&lt;h2 id="new-in-this-release">New in this release&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Adds&lt;/strong> automatic resizing of the observations datagrid.&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> header group by dataspace to the observations datagrid.&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> CLI version detection and prompt for upgrade on version, run, and add commands.&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> Support for parsing hex-encoded times and measurements. Use the &lt;code>time_format&lt;/code> of &lt;code>hex&lt;/code> or prefix with &lt;code>0x&lt;/code>.&lt;/li>
&lt;li>&lt;strong>Updates&lt;/strong> AI engine with improved training performance.&lt;/li>
&lt;li>&lt;strong>Updates&lt;/strong> Go and NPM dependencies.&lt;/li>
&lt;li>&lt;strong>Fixes&lt;/strong> detection of Spicepods in the &lt;code>Spicepods&lt;/code> directory, and a resulting error when loading a non-Spicepod file.&lt;/li>
&lt;li>&lt;strong>Fixes&lt;/strong> a potential &amp;ldquo;zip slip&amp;rdquo; security issue.&lt;/li>
&lt;li>&lt;strong>Fixes&lt;/strong> an issue where the AI engine may not gracefully shutdown.&lt;/li>
&lt;/ul>
&lt;h2 id="resources">Resources&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://docs.spiceai.org/getting-started/">Getting started with Spice.ai&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.spiceai.org/">Documentation&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/spiceai/quickstarts/blob/trunk/README.md">Quickstarts&lt;/a> and &lt;a href="https://github.com/spiceai/samples/blob/trunk/README.md">Samples&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="community">Community&lt;/h2>
&lt;p>Spice.ai started with the vision to make AI easy for developers. We are building Spice.ai in the open and with the community. Reach out on Discord or by email to get involved. We will also be starting a community call series soon!&lt;/p>
&lt;ul>
&lt;li>Discord: &lt;a href="https://discord.gg/kZnTfneP5u">https://discord.gg/kZnTfneP5u&lt;/a>&lt;/li>
&lt;li>Reddit: &lt;a href="https://www.reddit.com/r/spiceai">https://www.reddit.com/r/spiceai&lt;/a>&lt;/li>
&lt;li>Twitter: &lt;a href="https://twitter.com/spiceaihq">@SpiceAIHQ&lt;/a>&lt;/li>
&lt;li>Email: &lt;a href="mailto:hey@spiceai.io">hey@spiceai.io&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Posts: Spice.ai's approach to Time-Series AI</title><link>/posts/2021/11/18/spice.ais-approach-to-time-series-ai/</link><pubDate>Thu, 18 Nov 2021 00:00:00 +0000</pubDate><guid>/posts/2021/11/18/spice.ais-approach-to-time-series-ai/</guid><description>
&lt;p>The Spice.ai project strives to help developers build applications that leverage new AI advances which can be easily trained, deployed, and integrated. &lt;a href="/posts/2021/11/15/teaching-apps-how-to-learn-with-spicepods/">A previous blog post&lt;/a> introduced Spicepods: a declarative way to create AI applications with Spice.ai technology. While there are many libraries and platforms in the space, Spice.ai is focused on time-series data aligning to application-centric and frequently time-dependent data, and a &lt;a href="https://en.wikipedia.org/wiki/Reinforcement_learning">Reinforcement Learning&lt;/a> approach, which can be more developer-friendly than expensive, labeled &lt;a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning&lt;/a>.&lt;/p>
&lt;p>This post will discuss some of the challenges and directions for the technology we are developing.&lt;/p>
&lt;h3 id="time-series">Time Series&lt;/h3>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px; margin: auto" src="https://user-images.githubusercontent.com/19952490/142404970-de910848-cdb4-451b-a0d5-302c90215216.png" />
&lt;div style="font-size: 0.8rem; font-style: italic;">Figure 1. Time Series processing visualization: a time window is usually chosen to process part of the data stream&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>Time series AI has become more popular over recent years, and there is extensive literature on the subject, including time-series-focused neural networks. Research in this space points to the likelihood that there is no silver bullet, and a single approach to time series AI will not be sufficient. However, for developers, this can make building a product complex, as it comes with the challenge of exploring and evaluating many algorithms and approaches.&lt;/p>
&lt;p>A fundamental challenge of time series is the data itself. The shape and length are usually variable and can even be infinite (real-time streams of data). The volume of data required is often too much for simple and efficient machine learning algorithms such as &lt;a href="https://en.wikipedia.org/wiki/Decision_tree">Decision Trees&lt;/a>. This challenge makes Deep Learning popular to process such data. There are several types of neural networks that have been shown to work well with time series so let&amp;rsquo;s review some of the common classes:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Networks (CNN)&lt;/a>: CNN&amp;rsquo;s can only accept data with fixed lengths: even with the ability to pad the data, this is a major drawback for time-series data as a specific time window needs to be decided. Despite this limitation, they are the most efficient network to train (computation, data needed, time) and usually the smallest storage. CNN&amp;rsquo;s are very robust and used in image/video processing, making them a very good baseline to start with while also benefiting from refined and mature development over the years, such as with the very efficient MobileNet with depth-wise convolutions.&lt;/li>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">Recurrent Neural Networks (RNN)&lt;/a>: RNNs have been researched for several decades, and while they aren&amp;rsquo;t as fast to train as CNNs, they can be faster to apply as there is no need to feed a time window like CNNs if the desired input/output is in real-time (in a continuous fashion, also called &amp;lsquo;online). RNNs are proven to be very good in some situations, and many new models are being discovered.&lt;/li>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)">Transformers&lt;/a>: Most of the state-of-the-art results today have been made from transformers and their variations. They are very good at correlating sparse information. Popularized in the famous paper &lt;a href="https://arxiv.org/pdf/1706.03762.pdf">Attention is all you need&lt;/a>, transformers are proven to be flexible with high-performance in many classes (Vision Transformers, Perceiver, etc.). They suffer the same limitation as CNNs for the length of their input (fixed at training time), but they also have a disadvantage of not scaling well with the size of the data (quadratic growth with the length of the time series). They are also the most expensive network to train in general.&lt;/li>
&lt;/ul>
&lt;p>While not a complete representation of classes of neural networks, this list represents the areas of the most potential for Spice.ai&amp;rsquo;s time-series AI technology. We also see other interesting paradigms to explore when improving the core technology like Memory Augmented Neural Networks (MANN) or neural network-based Genetical Algorithms.&lt;/p>
&lt;h3 id="reinforcement-learning">Reinforcement Learning&lt;/h3>
&lt;p>Reinforcement Learning (RL) has grown steadily, especially in fields like robotics. Usually, RL doesn&amp;rsquo;t require as much data processing as Supervised Learning, where large datasets can be demanding for hardware and people alike. RL is more dynamic: agents aren&amp;rsquo;t trained to replicate a specific behaviors/output but explore and &amp;lsquo;exploit&amp;rsquo; their environment to maximize a given reward.&lt;/p>
&lt;p>Most of today&amp;rsquo;s research is based on environments the agent can interact with during the training process, known as online learning. Usually, efficient training processes have multiple agent/environment pairs training together and sharing their experiences. Having an environment for agents to interact enables different actions from the actual historical state known as &lt;strong>on-policy learning&lt;/strong>, and using only past experiences without an environment is &lt;strong>off-policy learning&lt;/strong>.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 600px; margin: auto" src="https://user-images.githubusercontent.com/19952490/142404987-cc6f0654-d2bd-496a-b6a4-52da19b9f912.png" />
&lt;div style="font-size: 0.8rem; font-style: italic;"> Figure 2. AI training without interacting with the environment (real world nor simulation). Only gathered data is used for training.&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>Spice.ai is initially taking an off-policy approach, where an environment (either pre-made or given by the user) is not required. Despite limiting the exploration of agents, this aligns to an application-centric approach as:&lt;/p>
&lt;ul>
&lt;li>Creating a real-world model or environment can be difficult and expensive to create, arguably even impossible.&lt;/li>
&lt;li>Off-policy learning is normally more efficient than on-policy (time/data and computation).&lt;/li>
&lt;/ul>
&lt;p>The Spice.ai approach to time series AI can be described as &amp;lsquo;Data-Driven&amp;rsquo; Reinforcement Learning. This domain is very exciting, and we are building upon excellent research that is being published. The &lt;a href="https://bair.berkeley.edu/">Berkeley Artificial Intelligence Research&lt;/a>&amp;rsquo;s blog shows the potential of this field and many other research entities that have made great discoveries like &lt;a href="https://deepmind.com/">DeepMind&lt;/a>, &lt;a href="https://openai.com/">Open AI&lt;/a>, &lt;a href="https://ai.facebook.com/">Facebook AI&lt;/a> and &lt;a href="https://ai.google/">Google AI&lt;/a> (among many others). We are inspired and are building upon all the research in Reinforcement Learning to develop core Spice.ai technology.&lt;/p>
&lt;p>If you are interested in Reinforcement Learning, we recommend following these blogs, and if you&amp;rsquo;d like to partner with us on the mission of making it easier to build intelligent applications by leveraging RL, we invite you to discuss with us on &lt;a href="https://discord.gg/kZnTfneP5u">Discord&lt;/a>, reach out on &lt;a href="https://twitter.com/SpiceAIHQ">Twitter&lt;/a> or &lt;a href="mailto:hey@spiceai.io">email us&lt;/a>.&lt;/p>
&lt;p>Corentin&lt;/p></description></item><item><title>Posts: Announcing the release of Spice.ai v0.4-alpha</title><link>/posts/2021/11/15/announcing-the-release-of-spice.ai-v0.4-alpha/</link><pubDate>Mon, 15 Nov 2021 00:00:00 +0000</pubDate><guid>/posts/2021/11/15/announcing-the-release-of-spice.ai-v0.4-alpha/</guid><description>
&lt;p>We are excited to announce the release of Spice.ai v0.4-alpha! ðŸ„â€â™‚ï¸&lt;/p>
&lt;p>Highlights include support for authoring reward functions in a code file, the ability to specify the time of recommendation, and ingestion support for transaction/correlation ids. Authoring reward functions in a code file is a significant improvement to the developer experience than specifying functions inline in the YAML manifest, and we are looking forward to your feedback on it!&lt;/p>
&lt;p>If you are new to Spice.ai, check out the &lt;a href="https://docs.spiceai.org/getting-started/">getting started guide&lt;/a> and star &lt;a href="https://github.com/spiceai/spiceai">spiceai/spiceai&lt;/a> on GitHub.&lt;/p>
&lt;h2 id="highlights-in-v04-alpha">Highlights in v0.4-alpha&lt;/h2>
&lt;h3 id="upgrade-using-spice-upgrade">Upgrade using spice upgrade&lt;/h3>
&lt;p>The &lt;code>spice upgrade&lt;/code> command was added in the v0.3.1-alpha release, so you can now upgrade from v0.3.1 to v0.4 by simply running &lt;code>spice upgrade&lt;/code> in your terminal. Special thanks to community member &lt;a href="https://github.com/Adm28">@Adm28&lt;/a> for contributing this feature!&lt;/p>
&lt;h3 id="reward-function-files">Reward Function Files&lt;/h3>
&lt;p>In addition to defining reward code inline, it is now possible to author reward code in functions in a separate Python file.&lt;/p>
&lt;p>The reward function file path is defined by the &lt;code>reward_funcs&lt;/code> property.&lt;/p>
&lt;p>A function defined in the code file is mapped to an action by authoring its name in the &lt;code>with&lt;/code> property of the relevant reward.&lt;/p>
&lt;p>Example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#204a87;font-weight:bold">training&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">reward_funcs&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">my_reward.py&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">rewards&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#204a87;font-weight:bold">reward&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">buy&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">with&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">buy_reward&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#204a87;font-weight:bold">reward&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">sell&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">with&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">sell_reward&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#204a87;font-weight:bold">reward&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">hold&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">with&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">hold_reward&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Learn more in the documentation: &lt;a href="https://docs.spiceai.org/concepts/rewards/external">docs.spiceai.org/concepts/rewards/external&lt;/a>&lt;/p>
&lt;h3 id="time-categories">Time Categories&lt;/h3>
&lt;p>Spice.ai can now learn from cyclical patterns, such as daily, weekly, or monthly cycles.&lt;/p>
&lt;p>To enable automatic cyclical field generation from the observation time, specify one or more time categories in the pod manifest, such as a &lt;code>month&lt;/code> or &lt;code>weekday&lt;/code> in the &lt;code>time&lt;/code> section.&lt;/p>
&lt;p>For example, by specifying &lt;code>month&lt;/code> the Spice.ai engine automatically creates a field in the AI engine data stream called &lt;code>time_month_{month}&lt;/code> with the value calculated from the month of which that timestamp relates.&lt;/p>
&lt;p>Example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#204a87;font-weight:bold">time&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">categories&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#000">month&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#000">dayofweek&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Supported category values are:
&lt;code>month&lt;/code> &lt;code>dayofmonth&lt;/code> &lt;code>dayofweek&lt;/code> &lt;code>hour&lt;/code>&lt;/p>
&lt;p>Learn more in the documentation: &lt;a href="https://docs.spiceai.org/reference/pod/#time">docs.spiceai.org/reference/pod/#time&lt;/a>&lt;/p>
&lt;h3 id="get-recommendation-for-a-specific-time">Get recommendation for a specific time&lt;/h3>
&lt;p>It is now possible to specify the time of recommendations fetched from the &lt;code>/recommendation&lt;/code> API.&lt;/p>
&lt;p>Valid times are from pod &lt;code>epoch_time&lt;/code> to &lt;code>epoch_time + period&lt;/code>.&lt;/p>
&lt;p>Previously the API only supported recommendations based on the time of the last ingested observation.&lt;/p>
&lt;p>Requests are made in the following format: &lt;code>GET http://localhost:8000/api/v0.1/pods/{pod}/recommendation?time={unix_timestamp}&lt;/code>&lt;/p>
&lt;p>An example for &lt;code>quickstarts/trader&lt;/code>&lt;/p>
&lt;p>&lt;code>GET http://localhost:8000/api/v0.1/pods/trader/recommendation?time=1605729600&lt;/code>&lt;/p>
&lt;p>Specifying &lt;code>{unix_timestamp}&lt;/code> as &lt;code>0&lt;/code> will return a recommendation based on the latest data. An invalid &lt;code>{unix_timestamp}&lt;/code> will return a result that has the valid time range in the error message:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-json" data-lang="json">&lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;response&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;result&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;invalid_recommendation_time&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;message&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;The time specified (1610060201) is outside of the allowed range: (1610057600, 1610060200)&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;error&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#204a87;font-weight:bold">true&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="new-in-this-release">New in this release&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Adds&lt;/strong> time categories configuration to the pod manifest to enable learning from cyclical patterns in data - e.g. hour, day of week, day of month, and month&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> support for defining reward functions in a rewards functions code file.&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> the ability to specify recommendation time making it possible to now see which action Spice.ai recommends at any time during the pod period.&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> support for ingestion of transaction/correlation identifiers (e.g. &lt;code>order_id&lt;/code>, &lt;code>trace_id&lt;/code>) in the pod manifest.&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> validation for invalid dataspace names in the pod manifest.&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> the ability to resize columns to the dashboard observation data grid.&lt;/li>
&lt;li>&lt;strong>Updates&lt;/strong> to TensorFlow 2.7 and Keras 2.7&lt;/li>
&lt;li>&lt;strong>Fixes&lt;/strong> a bug where data processors were using data connector params&lt;/li>
&lt;li>&lt;strong>Fixes&lt;/strong> a dashboard issue in the pod observations data grid where a column might not be shown.&lt;/li>
&lt;li>&lt;strong>Fixes&lt;/strong> a crash on pod load if the &lt;code>training&lt;/code> section is not included in the manifest.&lt;/li>
&lt;li>&lt;strong>Fixes&lt;/strong> an issue where data manager stats errors were incorrectly being printed to console.&lt;/li>
&lt;li>&lt;strong>Fixes&lt;/strong> an issue where selectors may not match due to surrounding whitespace.&lt;/li>
&lt;/ul>
&lt;h2 id="resources">Resources&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://docs.spiceai.org/getting-started/">Getting started with Spice.ai&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.spiceai.org/">Documentation&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/spiceai/quickstarts/blob/trunk/README.md">Quickstarts&lt;/a> and &lt;a href="https://github.com/spiceai/samples/blob/trunk/README.md">Samples&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="community">Community&lt;/h2>
&lt;p>Spice.ai started with the vision to make AI easy for developers. We are building Spice.ai in the open and with the community. Reach out on Discord or by email to get involved. We will also be starting a community call series soon!&lt;/p>
&lt;ul>
&lt;li>Discord: &lt;a href="https://discord.gg/kZnTfneP5u">https://discord.gg/kZnTfneP5u&lt;/a>&lt;/li>
&lt;li>Reddit: &lt;a href="https://www.reddit.com/r/spiceai">https://www.reddit.com/r/spiceai&lt;/a>&lt;/li>
&lt;li>Twitter: &lt;a href="https://twitter.com/spiceaihq">@SpiceAIHQ&lt;/a>&lt;/li>
&lt;li>Email: &lt;a href="mailto:hey@spiceai.io">hey@spiceai.io&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Posts: Teaching Apps how to Learn with Spicepods</title><link>/posts/2021/11/15/teaching-apps-how-to-learn-with-spicepods/</link><pubDate>Mon, 15 Nov 2021 00:00:00 +0000</pubDate><guid>/posts/2021/11/15/teaching-apps-how-to-learn-with-spicepods/</guid><description>
&lt;p>The last post in this series, &lt;a href="https://blog.spiceai.org/posts/2021/11/05/making-apps-that-learn-and-adapt/">Making Apps that Learn and Adapt&lt;/a>, described the shift from building AI/ML solutions to building apps that learn and adapt. But, how does the app learn? And as a developer, how do I teach it what it should learn?&lt;/p>
&lt;p>With &lt;a href="https://spiceai.org">Spice.ai&lt;/a>, we teach the app how to learn using a Spicepod.&lt;/p>
&lt;p>Imagine you own a restaurant. You created a menu, hired staff, constructed the kitchen and dining room, and got off to a great start when it first opened. However, over the years, your customers' tastes changed, you&amp;rsquo;ve had to make compromises on ingredients, and there&amp;rsquo;s a hot new place down the street&amp;hellip; business is stagnating, and you know that you need to make some changes to stay competitive.&lt;/p>
&lt;p>You have a few options. First, you could gather all the data, such as customer surveys, seasonal produce metrics, and staff performance profiles. You may even hire outside consultants. You then take this data to your office, and after spending some time organizing, filtering, and collating it, you&amp;rsquo;ve discovered an insight! Your seafood dishes sell poorly and cost the most&amp;hellip; you are losing money! You spend several weeks or months perfecting a new menu, which you roll out with much fanfare! And thenâ€¦ business is still poor. What!? How could this be? It was a data-driven approach! You start the process again. While this approach is a worthy option, it has long latency from data to learning to implementation.&lt;/p>
&lt;p>Another option is to build real-time learning and adaption directly into the restaurant. Imagine a staff member whose sole job was learning and adapting how the restaurant should operate; lets name them Blue. You write a guide for Blue that defines certain goal metrics, like customer food ratings, staff happiness, and of course, profit. Blue tracks each dish served, from start to finish, from who prepared it to its temperature, its costs, and its final customer taste rating. Blue not only learns from each customer review as each dish is consumed but also how dish preparation affects other goal metrics, like profitability. The restaurant staff consults Blue to determine any adjustments to improve goal metrics as they work. The latency from data to learning, to adaption, has been reduced, from weeks or months to minutes. This option, of course, is not feasible for most restaurants, but software applications can use this approach. Blue and his instructions are analogous to the Spice.ai runtime and manifest.&lt;/p>
&lt;p>In the Spice.ai model, developers teach the app how to learn by describing goals and rewarding its actions, much like how a parent might teach a child. As these rewards are applied in training, the app learns what actions maximize its rewards towards the defined goals.&lt;/p>
&lt;p>Returning to the restaurant example, you can think of the Spice.ai runtime as Blue, and Spicepod manifests as the guide on how Blue should learn. Individual staff members would consult with Blue for ongoing recommendations on decisions to make and how to act. These goals and rewards are defined in &lt;strong>Spicepods&lt;/strong> or &amp;ldquo;pods&amp;rdquo; for short. Spicepods are packages of configuration that describe the application&amp;rsquo;s goals and how it should learn from data. Although it&amp;rsquo;s not a direct analogy, Spicepods and their manifests can be conceptualized similar to Docker containers and Dockerfiles. In contrast, Dockerfiles define the packaging of your app, Spicepods specify the packaging of your app&amp;rsquo;s learning and data.&lt;/p>
&lt;p>&lt;strong>Anatomy of a Spicepod&lt;/strong>&lt;/p>
&lt;p>A Spicepod consists of:&lt;/p>
&lt;ul>
&lt;li>A required YAML manifest that describes how the pod should learn from data&lt;/li>
&lt;li>Optional seed data&lt;/li>
&lt;li>Learned model/state&lt;/li>
&lt;li>Performance telemetry and metrics&lt;/li>
&lt;/ul>
&lt;p>Developers author Spicepods using the &lt;code>spice&lt;/code> CLI command such as with &lt;code>spice pod init &amp;lt;name&amp;gt;&lt;/code> or simply by creating a manifest file such as &lt;code>mypod.yaml&lt;/code> in the &lt;code>spicepods&lt;/code> directory of their application.&lt;/p>
&lt;p>Here&amp;rsquo;s an example of the &lt;a href="https://github.com/spiceai/quickstarts/tree/trunk/tweet-recommendation/README.md">Tweet Recommendation Quickstart&lt;/a> Spicepod manifest.&lt;/p>
&lt;img width="400" alt="tweet-recommendation-manifest" src="https://user-images.githubusercontent.com/80174/141739579-9cf7b971-7637-43bc-b661-89115e3b1b59.png">
&lt;p>&lt;em>A screenshot of the Spicepod manifest for the Tweet Recommendation Quickstart&lt;/em>&lt;/p>
&lt;p>You can see the data definitions under &lt;code>dataspaces&lt;/code>, the actions the application may take under &lt;code>actions&lt;/code>, and their rewards when training.&lt;/p>
&lt;p>In the next post, I&amp;rsquo;ll walk through in detail each section of the pod manifest. In the meantime, you can review the documentation for a complete reference of the &lt;a href="https://docs.spiceai.org/reference/pod/">Spicepod manifest syntax&lt;/a>.&lt;/p>
&lt;p>&lt;strong>Spicepods as packages&lt;/strong>&lt;/p>
&lt;p>On disk, Spicepods are generally layouts of a manifest file, seed data, and trained models, but they can also be exported as zipped packages.&lt;/p>
&lt;img width="235" alt="spicepod-layout" src="https://user-images.githubusercontent.com/80174/141739662-7be361fe-aa79-4408-bb3d-311fd0f849eb.png">
&lt;p>&lt;em>A screenshot of the Spicepod layout for the trader quickstart application&lt;/em>&lt;/p>
&lt;p>When the runtime exports a Spicepod using the &lt;code>spice export&lt;/code> command, it is saved with a &lt;code>.spicepod&lt;/code> extension. It can then be shared, archived, or imported into another instance of the Spice.ai runtime.&lt;/p>
&lt;p>Soon, we also expect to enable publishing of &lt;code>.spicepods&lt;/code> to spicerack.org, from where community-created Spicepods can easily be added to your application using &lt;code>spice add &amp;lt;pod name&amp;gt;&lt;/code> (currently, only Spice AI published pods are available on spicerack.org).&lt;/p>
&lt;p>Treating Spicepods as packages and enabling their sharing and distribution through spicerack.org will help developers share their &amp;ldquo;restaurant guides&amp;rdquo; and build upon each other&amp;rsquo;s work, much like they do with npmjs.org or pypi.org. In this way, developers can together build better and more intelligent applications.&lt;/p>
&lt;p>In the next post, we&amp;rsquo;ll dive deeper into authoring a Spicepod manifest to create an intelligent application. Follow &lt;a href="https://twitter.com/SpiceAIHQ">@SpiceAIHQ&lt;/a> on Twitter to get an update when we post.&lt;/p>
&lt;p>If you haven&amp;rsquo;t already, read the next the first post in the series, &lt;a href="https://blog.spiceai.org/posts/2021/11/05/making-apps-that-learn-and-adapt/">Making Apps that Learn and Adapt&lt;/a>.&lt;/p>
&lt;h3 id="learn-more-and-contribute">Learn more and contribute&lt;/h3>
&lt;p>Building intelligent apps that leverage AI is still way too hard, even for advanced developers. Our mission is to make this as easy as creating a modern web page. If the vision resonates with you, join us!&lt;/p>
&lt;p>Our &lt;a href="https://github.com/spiceai/spiceai/blob/trunk/docs/ROADMAP.md">Spice.ai Roadmap&lt;/a> is public, and now that we have launched, the project and work are open for collaboration.&lt;/p>
&lt;p>If you are interested in partnering, we&amp;rsquo;d love to talk. Try out &lt;a href="https://spiceai.org">Spice.ai&lt;/a>, &lt;a href="mailto:hey@spiceai.io">email us&lt;/a> &amp;ldquo;hey,&amp;rdquo; get in touch on &lt;a href="https://discord.gg/kZnTfneP5u">Discord&lt;/a>, or reach out on &lt;a href="https://twitter.com/SpiceAIHQ">Twitter&lt;/a>.&lt;/p>
&lt;p>We are just getting started! ðŸš€&lt;/p>
&lt;p>Luke&lt;/p></description></item><item><title>Posts: Making Apps That Learn And Adapt</title><link>/posts/2021/11/05/making-apps-that-learn-and-adapt/</link><pubDate>Fri, 05 Nov 2021 00:00:00 +0000</pubDate><guid>/posts/2021/11/05/making-apps-that-learn-and-adapt/</guid><description>
&lt;p>In the &lt;a href="https://blog.spiceai.org/posts/2021/09/07/introducing-spice.ai-open-source-time-series-ai-for-developers/">Spice.ai announcement blog post&lt;/a>, we shared some of the inspiration for the project stemming from challenges in applying and integrating AI/ML into a neurofeedback application. Building upon those ideas, in this post, we explore the shift in approach from a focus of data science and machine learning (ML) to apps that learn and adapt.&lt;/p>
&lt;p>As a developer, I&amp;rsquo;ve followed the AI/ML space with keen interest and been impressed with the advances and announcements that only seem to be increasing. &lt;a href="https://stateof.ai">stateof.ai&lt;/a> recently published its 2021 report, and once again, it&amp;rsquo;s been another great year of progress. At the same time, it&amp;rsquo;s still more challenging than ever for mainstream developers to integrate AI/ML into their applications. For most developers, where AI/ML is not their full-time job, and without the support of a dedicated ML team, creating and developing an intelligent application that learns and adapts is still too hard.&lt;/p>
&lt;p>Most solutions on the market, even those that claim they are for developers, focus on helping make ML easier instead of making it easier to build applications. These solutions have been great for advancing ML itself but have not helped developers leverage ML in their apps to make them intelligent. Even when a developer successfully integrates ML into an application, it might make that application smart, but often does not help the app continue to learn and adapt over time.&lt;/p>
&lt;p>Traditionally, the industry has viewed AI/ML as separate from the application. A pipeline, service, or team is provided with data, which trains on that data, and can then provide answers or insights. These solutions are often created with a waterfall-like approach, gathering and defining requirements, designing, implementing, testing, and deploying. Sometimes this process can take months or even years.&lt;/p>
&lt;p>With Spice.ai, we propose a new approach to building applications. By bringing AI/ML alongside your compute and data and incorporating it as part of your application, the app can incrementally adopt recommendations from the AI engine and in addition the AI engine can learn from the application&amp;rsquo;s data and actions. This approach shifts from waterfall-like to agile-like, where the AI engine ingests streams of application and external data, along with the results of the application&amp;rsquo;s actions, to continuously learn. This virtuous feedback cycle from the app to the AI engine and back again enables the app to get smarter and adapt over time. In this approach, building your application &lt;em>is&lt;/em> developing the ML.&lt;/p>
&lt;p>Being part of the application is not just conceptual. Development teams deploy the Spice.ai runtime and AI engine with the application as a sidecar or microservice, enabling the app services and runtime to work together and for data to be kept application local. A developer teaches the AI engine how to learn by defining application goals and rewards for actions the application takes. The AI Engine observes the application and the consequences of its actions, which feeds into its experience. As the AI engine learns, the application can adapt.&lt;/p>
&lt;div style="display: flex; justify-content: center; padding: 5px;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 400px;" src="https://user-images.githubusercontent.com/80174/140449760-97974f3c-8a78-4ea2-9ec5-843dc3cff5b6.png" />
&lt;/div>
&lt;/div>
&lt;p>As developers shift from thinking about disparate applications and ML to building applications where AI that learns and adapts is integrated as a core part of the application logic, a new class of intelligent applications will emerge. And as technical talent becomes even more scarce, applications built this way will be necessary, not just to be competitive but to be even built at all.&lt;/p>
&lt;p>In the next post, I&amp;rsquo;ll discuss the concept of Spicepods, bundles of configuration that describes how the application should learn, and how the Spice.ai runtime hosts and uses them to help developers make applications that learn.&lt;/p>
&lt;h3 id="learn-more-and-contribute">Learn more and contribute&lt;/h3>
&lt;p>Building intelligent apps that leverage AI is still way too hard, even for advanced developers. Our mission is to make this as easy as creating a modern web page. If the vision resonates with you, join us!&lt;/p>
&lt;p>Our &lt;a href="https://github.com/spiceai/spiceai/blob/trunk/docs/ROADMAP.md">Spice.ai Roadmap&lt;/a> is public, and now that we have launched, the project and work are open for collaboration.&lt;/p>
&lt;p>If you are interested in partnering, we&amp;rsquo;d love to talk. Try out &lt;a href="https://spiceai.org">Spice.ai&lt;/a>, &lt;a href="mailto:hey@spiceai.io">email us&lt;/a> &amp;ldquo;hey,&amp;rdquo; get in touch on &lt;a href="https://discord.gg/kZnTfneP5u">Discord&lt;/a>, or reach out on &lt;a href="https://twitter.com/SpiceAIHQ">Twitter&lt;/a>.&lt;/p>
&lt;p>We are just getting started! ðŸš€&lt;/p>
&lt;p>Luke&lt;/p></description></item><item><title>Posts: Announcing the release of Spice.ai v0.3.1-alpha</title><link>/posts/2021/11/02/announcing-the-release-of-spice.ai-v0.3.1-alpha/</link><pubDate>Tue, 02 Nov 2021 00:00:00 +0000</pubDate><guid>/posts/2021/11/02/announcing-the-release-of-spice.ai-v0.3.1-alpha/</guid><description>
&lt;p>We are excited to announce the release of Spice.ai v0.3.1-alpha! ðŸŽƒ&lt;/p>
&lt;p>This point release focuses on fixes and improvements to v0.3-alpha. Highlights include the ability to specify both seed and runtime data, to select custom named fields for &lt;code>time&lt;/code> and &lt;code>tags&lt;/code>, a new &lt;code>spice upgrade&lt;/code> command and several bug fixes.&lt;/p>
&lt;p>A special acknowledgment to &lt;a href="https://github.com/Adm28">@Adm28&lt;/a>, who added the new &lt;code>spice upgrade&lt;/code> command, which enables the CLI to self-update, which in turn will auto-update the runtime.&lt;/p>
&lt;h2 id="highlights-in-v031-alpha">Highlights in v0.3.1-alpha&lt;/h2>
&lt;h3 id="upgrade-command">Upgrade command&lt;/h3>
&lt;p>The CLI can now be updated using the new &lt;code>spice upgrade&lt;/code> command. This command will check for, download, and install the latest Spice.ai CLI release, which will become active on it&amp;rsquo;s next run.&lt;/p>
&lt;p>When run, the CLI will check for the matching version of the Spice.ai runtime, and will automatically download and install it as necessary.&lt;/p>
&lt;p>The version of both the Spice.ai CLI and runtime can be checked with the &lt;code>spice version&lt;/code> CLI command.&lt;/p>
&lt;h3 id="seed-data">Seed data&lt;/h3>
&lt;p>When working with streaming data sources, like market prices, it&amp;rsquo;s often also useful to seed the dataspace with historical data. Spice.ai enables this with the new &lt;code>seed_data&lt;/code> node in the dataspace configuration. The syntax is exactly the same as the &lt;code>data&lt;/code> syntax. For example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#204a87;font-weight:bold">dataspaces&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#204a87;font-weight:bold">from&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">coinbase&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">name&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">btcusd&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">seed_data&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">connector&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">file&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">params&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">path&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">path/to/seed/data.csv&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">processor&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">name&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">csv&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">data&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">connector&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">coinbase&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">params&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">product_ids&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">BTC-USD&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">processor&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">name&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">json&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The seed data will be fetched first, before the runtime data is initialized. Both sets of connectors and processors use the dataspace scoped &lt;code>measurements&lt;/code>, &lt;code>categories&lt;/code> and &lt;code>tags&lt;/code> for processing, and both data sources are merged in pod-scoped observation timeline.&lt;/p>
&lt;h3 id="time-field-selectors">Time field selectors&lt;/h3>
&lt;p>Before v0.3.1-alpha, data was required to include a specific &lt;code>time&lt;/code> field. In v0.3.1-alpha, the &lt;a href="https://github.com/spiceai/data-components-contrib/blob/trunk/dataprocessors/json/README.md">JSON&lt;/a> and &lt;a href="https://github.com/spiceai/data-components-contrib/tree/trunk/dataprocessors/csv">CSV&lt;/a> data processors now support the ability to select a specific field to populate the time field. An example selector to use the &lt;code>created_at&lt;/code> column for &lt;code>time&lt;/code> is:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#204a87;font-weight:bold">data&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">processor&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">name&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">csv&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">params&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">time_selector&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">created_at&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="tag-field-selectors">Tag field selectors&lt;/h3>
&lt;p>Before v0.3.1-alpha, &lt;a href="https://docs.spiceai.org/reference/pod/#dataspacestags">tags&lt;/a> were required to be placed in a &lt;code>_tags&lt;/code> field. In v0.3.1-alpha, any field can now be selected to populate tags. Tags are pod-unique string values, and the union of all selected fields will make up the resulting tag list. For example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#204a87;font-weight:bold">dataspace&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">from&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">twitter&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">name&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">tweets&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">tags&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">selectors&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#000">tags&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#000">author_id&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">values&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#000">spiceaihq&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#000">spicy&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="new-in-this-release">New in this release&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Adds&lt;/strong> a new &lt;code>spice upgrade&lt;/code> command for self-upgrade of the Spice.ai CLI.&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> a new &lt;code>seed_data&lt;/code> node to the dataspace configuration, enabling the dataspace to be seeded with an alternative source of data.&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> the ability to select a custom time field in JSON and CSV data processors with the &lt;code>time_selector&lt;/code> parameter.&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> the ability to select custom tag fields in the dataspace configuration with &lt;code>selectors&lt;/code> list.&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> error reporting for AI engine crashes, where previously it would fail silently.&lt;/li>
&lt;li>&lt;strong>Fixes&lt;/strong> the dashboard pods list from &amp;ldquo;jumping&amp;rdquo; around due to being unsorted.&lt;/li>
&lt;li>&lt;strong>Fixes&lt;/strong> rare cases where categorical data might be sent to the AI engine in the wrong format.&lt;/li>
&lt;/ul>
&lt;h2 id="resources">Resources&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://docs.spiceai.org/getting-started/">Getting started with Spice.ai&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.spiceai.org/">Documentation&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/spiceai/quickstarts/blob/trunk/README.md">Quickstarts&lt;/a> and &lt;a href="https://github.com/spiceai/samples/blob/trunk/README.md">Samples&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="community">Community&lt;/h2>
&lt;p>Spice.ai started with the vision to make AI easy for developers. We are building Spice.ai in the open and with the community. Reach out on Discord or by email to get involved. We will also be starting a community call series soon!&lt;/p>
&lt;ul>
&lt;li>Discord: &lt;a href="https://discord.gg/kZnTfneP5u">https://discord.gg/kZnTfneP5u&lt;/a>&lt;/li>
&lt;li>Reddit: &lt;a href="https://www.reddit.com/r/spiceai">https://www.reddit.com/r/spiceai&lt;/a>&lt;/li>
&lt;li>Twitter: &lt;a href="https://twitter.com/spiceaihq">@SpiceAIHQ&lt;/a>&lt;/li>
&lt;li>Email: &lt;a href="mailto:hey@spiceai.io">hey@spiceai.io&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Posts: Spice.ai v0.3-alpha is now available</title><link>/posts/2021/10/26/spice.ai-v0.3-alpha-is-now-available/</link><pubDate>Tue, 26 Oct 2021 00:00:00 +0000</pubDate><guid>/posts/2021/10/26/spice.ai-v0.3-alpha-is-now-available/</guid><description>
&lt;p>We are excited to announce the release of Spice.ai v0.3-alpha! ðŸŽ‰&lt;/p>
&lt;p>This release adds support for ingestion, automatic encoding, and training of categorical data, enabling more use-cases and datasets beyond just numerical measurements. For example, perhaps you want to learn from data that includes a category of t-shirt sizes, with discrete values, such as small, medium, and large. The v0.3 engine now supports this and automatically encodes the categorical string values into numerical values that the AI engine can use. Also included is a preview of data visualizations in the dashboard, which is helpful for developers as they author Spicepods and dataspaces.&lt;/p>
&lt;div style="display: flex; justify-content: center;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 500px;" src="https://user-images.githubusercontent.com/80174/138641533-612d1541-a90e-4279-b4f9-2872e02619d6.png" />
&lt;em style="text-align: center">A screenshot of the data visualization preview&lt;/em>
&lt;/div>
&lt;/div>
&lt;p>A special acknowledgment to &lt;a href="https://github.com/sboorlagadda">@sboorlagadda&lt;/a>, who submitted the first Spice.ai feature contribution from the community ever! He added the ability to list pods from the CLI with the new &lt;code>spice pods list&lt;/code> command. Thank you, &lt;a href="https://github.com/sboorlagadda">@sboorlagadda&lt;/a>!!!&lt;/p>
&lt;div style="display: flex; justify-content: center;">
&lt;div style="display: flex; flex-direction: column;">
&lt;img style="max-width: 500px;" src="https://user-images.githubusercontent.com/80174/138642457-a8f254ce-6b4f-4836-b921-f0eb0feadeab.png" />
&lt;em style="text-align: center">A screenshot of the new spice pods list command and output.&lt;/em>
&lt;/div>
&lt;/div>
&lt;p>If you are new to Spice.ai, check out the &lt;a href="https://docs.spiceai.org/getting-started/">getting started guide&lt;/a> and star &lt;a href="https://github.com/spiceai/spiceai">spiceai/spiceai&lt;/a> on GitHub.&lt;/p>
&lt;h2 id="highlights-in-v03-alpha">Highlights in v0.3-alpha&lt;/h2>
&lt;h3 id="categorical-data">Categorical data&lt;/h3>
&lt;p>In v0.1, the runtime and AI engine only supported ingesting numerical data. In v0.2, tagged data was accepted and automatically encoded into fields available for learning. In this release, v0.3, categorical data can now also be ingested and automatically encoded into fields available for learning. This is a &lt;em>breaking change&lt;/em> with the format of the manifest changing separating numerical measurements and categorical data.&lt;/p>
&lt;p>Pre-v0.3, the manifest author specified numerical data using the &lt;code>fields&lt;/code> node.&lt;/p>
&lt;p>In v0.3, numerical data is now specified under &lt;code>measurements&lt;/code> and categorical data under &lt;code>categories&lt;/code>. E.g.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#204a87;font-weight:bold">dataspaces&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#204a87;font-weight:bold">from&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">event&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">name&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">stream&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">measurements&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#204a87;font-weight:bold">name&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">duration&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">selector&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">length_of_time&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">fill&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">none&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#204a87;font-weight:bold">name&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">guest_count&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">selector&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">num_guests&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">fill&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">none&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">categories&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#204a87;font-weight:bold">name&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">event_type&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">values&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#000">dinner&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#000">party&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#204a87;font-weight:bold">name&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">target_audience&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">values&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#000">employees&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#000">investors&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">tags&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#000">tagA&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#000">tagB&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="data-visualizations-preview">Data visualizations preview&lt;/h3>
&lt;p>A top piece of community feedback was the ability to visualize data. After first running Spice.ai, we&amp;rsquo;d often hear from developers, &amp;ldquo;how do I see the data?&amp;rdquo;. A preview of data visualizations is now included in the dashboard on the pod page.&lt;/p>
&lt;h3 id="listing-pods">Listing pods&lt;/h3>
&lt;p>Once the Spice.ai runtime has started, you can view the loaded pods on the dashboard and fetch them via API call &lt;a href="http://localhost:8000/api/v0.1/pods">localhost:8000/api/v0.1/pods&lt;/a>. To make it even easier, we&amp;rsquo;ve added the ability to list them via the CLI with the new &lt;code>spice pods list&lt;/code> command, which shows the list of pods and their manifest paths.&lt;/p>
&lt;h3 id="coinbase-data-connector">Coinbase data connector&lt;/h3>
&lt;p>A new &lt;a href="https://github.com/spiceai/data-components-contrib/blob/trunk/dataconnectors/coinbase/README.md">Coinbase data connector&lt;/a> is included in v0.3, enabling the streaming of live market ticker prices from Coinbase Pro. Enable it by specifying the &lt;code>coinbase&lt;/code> data connector and providing a list of Coinbase Pro product ids. E.g. &amp;ldquo;BTC-USD&amp;rdquo;. A new sample which demonstrates is also available with its associated Spicepod available from the spicerack.org registry. Get it with &lt;code>spice add samples/trader&lt;/code>&lt;/p>
&lt;h3 id="tweet-recommendation-quickstart">Tweet Recommendation Quickstart&lt;/h3>
&lt;p>A new &lt;a href="https://github.com/spiceai/quickstarts/blob/trunk/tweet-recommendation/README.md">Tweet Recommendation Quickstart&lt;/a> has been added. Given past tweet activity and metrics of a given account, this app can recommend when to tweet, comment, or retweet to maximize for like count, interaction rates, and outreach of said given Twitter account.&lt;/p>
&lt;h3 id="trader-sample">Trader Sample&lt;/h3>
&lt;p>A new &lt;a href="https://github.com/spiceai/samples/blob/trunk/trader/README.md">Trader Sample&lt;/a> has been added in addition to the Trader Quickstart. The sample uses the new &lt;a href="https://github.com/spiceai/data-components-contrib/blob/trunk/dataconnectors/coinbase/README.md">Coinbase data connector&lt;/a> to stream live Coinbase Pro ticker data for learning.&lt;/p>
&lt;h2 id="new-in-this-release">New in this release&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Adds&lt;/strong> support for ingesting, encoding, and training on categorical data. v0.3 uses one-hot-encoding.&lt;/li>
&lt;li>&lt;strong>Changes&lt;/strong> Spicepod manifest fields node to &lt;a href="docs.spiceai.org/reference/pod/#dataspacesmeasurements">measurements&lt;/a> and add the &lt;a href="docs.spiceai.org/reference/pod/#dataspacescategories">categories&lt;/a> node.&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> the ability to select a field from the source data and map it to a different field name in the dataspace. See &lt;a href="docs.spiceai.org/reference/pod/#dataspacesmeasurementsselector">an example for measurements&lt;/a> in docs.&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> support for JSON content type when fetching from the &lt;code>/observations&lt;/code> API. Previously, only CSV was supported.&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> a preview version of data visualizations to the dashboard. The grid has several limitations, one of which is it currently cannot be resized.&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> the ability to select which learning algorithm to use via the CLI, the API, and specified in the Spicepod manifest. Possible choices are currently &amp;ldquo;vpg&amp;rdquo;, Vanilla Policy Gradient and &amp;ldquo;dql&amp;rdquo;, Deep Q-Learning. Shout out to &lt;a href="https://github.com/corentin-pro">@corentin-pro&lt;/a>, who added this feature on his second day on the team!&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> the ability to list loaded pods with the CLI command spice pods list.&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> a new &lt;a href="https://github.com/spiceai/data-components-contrib/blob/trunk/dataconnectors/coinbase/README.md">coinbase data connector&lt;/a> for Coinbase Pro market prices.&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> a new &lt;a href="https://github.com/spiceai/quickstarts/blob/trunk/tweet-recommendation/README.md">Tweet Recommendation Quickstart&lt;/a>.&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> a new &lt;a href="https://github.com/spiceai/samples/blob/trunk/trader/README.md">Trader Sample&lt;/a>.&lt;/li>
&lt;li>&lt;strong>Fixes&lt;/strong> bug where the &lt;code>/observations&lt;/code> endpoint was not providing fully qualified field names.&lt;/li>
&lt;li>&lt;strong>Fixes&lt;/strong> issue where debugging messages were printed when using spice add.&lt;/li>
&lt;/ul>
&lt;h2 id="resources">Resources&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://docs.spiceai.org/getting-started/">Getting started with Spice.ai&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.spiceai.org/">Documentation&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/spiceai/quickstarts/blob/trunk/README.md">Quickstarts&lt;/a> and &lt;a href="https://github.com/spiceai/samples/blob/trunk/README.md">Samples&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="community">Community&lt;/h2>
&lt;p>Spice.ai started with the vision to make AI easy for developers. We are building Spice.ai in the open and with the community. Reach out on Discord or by email to get involved. We will also be starting a community call series soon!&lt;/p>
&lt;ul>
&lt;li>Discord: &lt;a href="https://discord.gg/kZnTfneP5u">https://discord.gg/kZnTfneP5u&lt;/a>&lt;/li>
&lt;li>Reddit: &lt;a href="https://www.reddit.com/r/spiceai">https://www.reddit.com/r/spiceai&lt;/a>&lt;/li>
&lt;li>Twitter: &lt;a href="https://twitter.com/spiceaihq">@SpiceAIHQ&lt;/a>&lt;/li>
&lt;li>Email: &lt;a href="mailto:hey@spiceai.io">hey@spiceai.io&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Posts: Announcing the release of Spice.ai v0.2.1-alpha</title><link>/posts/2021/10/12/announcing-the-release-of-spice.ai-v0.2.1-alpha/</link><pubDate>Tue, 12 Oct 2021 00:00:00 +0000</pubDate><guid>/posts/2021/10/12/announcing-the-release-of-spice.ai-v0.2.1-alpha/</guid><description>
&lt;p>Announcing the release of Spice.ai v0.2.1-alpha! ðŸšš&lt;/p>
&lt;p>This point release focuses on fixes and improvements to v0.2-alpha. Highlights include the ability to specify how missing data should be treated and a new production mode for &lt;code>spiced&lt;/code>.&lt;/p>
&lt;p>This release supports the ability to specify how the runtime should treat missing data. Previous releases filled missing data with the last value (or initial value) in the series. While this makes sense for some data, i.e., market prices of a stock or cryptocurrency, it does not make sense for discrete data, i.e., ratings. In v0.2.1, developers can now add the &lt;code>fill&lt;/code> parameter on a dataspace field to specify the behavior. This release supports fill types &lt;code>previous&lt;/code> and &lt;code>none&lt;/code>. The default is &lt;code>previous&lt;/code>.&lt;/p>
&lt;p>Example in a manifest:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#204a87;font-weight:bold">dataspaces&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#204a87;font-weight:bold">from&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">twitter&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">name&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">tweets&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">fields&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#204a87;font-weight:bold">name&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">likes&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">fill&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">none&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#8f5902;font-style:italic"># The new fill parameter&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>spiced&lt;/code> now defaults to a new production mode when run standalone (not via the CLI), with development mode now explicitly set with the &lt;code>--development&lt;/code> flag. Production mode does not activate development time features, such as the Spicepod file watcher. The CLI always runs &lt;code>spiced&lt;/code> in development mode as it is not expected to be used in production deployments.&lt;/p>
&lt;h2 id="new-in-this-release">New in this release&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Adds&lt;/strong> a &lt;code>fill&lt;/code> parameter to dataspace fields to specify how missing values should be treated.&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> the ability to specify the fill behavior of empty values in a dataspace.&lt;/li>
&lt;li>&lt;strong>Simplifies&lt;/strong> releases with a single &lt;code>spiceai&lt;/code> release instead of separate &lt;code>spice&lt;/code> and &lt;code>spiced&lt;/code> releases.&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> an explicit &lt;strong>development&lt;/strong> mode to &lt;code>spiced&lt;/code>. Production mode does not activate the file watcher.&lt;/li>
&lt;li>&lt;strong>Fixes&lt;/strong> a bug when the pod parameter &lt;code>epoch_time&lt;/code> was not set which would cause data not to be sent to the AI engine.&lt;/li>
&lt;li>&lt;strong>Fixes&lt;/strong> a bug where the User-Agent was not set correctly from CLI calls to api.spicerack.org&lt;/li>
&lt;/ul>
&lt;h2 id="resources">Resources&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://docs.spiceai.org/getting-started/">Getting started with Spice.ai&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.spiceai.org/">Documentation&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/spiceai/quickstarts/blob/trunk/README.md">Quickstarts&lt;/a> and &lt;a href="https://github.com/spiceai/samples/blob/trunk/README.md">Samples&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="community">Community&lt;/h2>
&lt;p>Spice.ai started with the vision to make AI easy for developers. We are building Spice.ai in the open and with the community. Reach out on Discord or by email to get involved. We will also be starting a community call series soon!&lt;/p>
&lt;ul>
&lt;li>Discord: &lt;a href="https://discord.gg/kZnTfneP5u">https://discord.gg/kZnTfneP5u&lt;/a>&lt;/li>
&lt;li>Reddit: &lt;a href="https://www.reddit.com/r/spiceai">https://www.reddit.com/r/spiceai&lt;/a>&lt;/li>
&lt;li>Twitter: &lt;a href="https://twitter.com/spiceaihq">@SpiceAIHQ&lt;/a>&lt;/li>
&lt;li>Email: &lt;a href="mailto:hey@spiceai.io">hey@spiceai.io&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Posts: Spice.ai v0.2-alpha is now available</title><link>/posts/2021/10/04/spice.ai-v0.2-alpha-is-now-available/</link><pubDate>Mon, 04 Oct 2021 00:00:00 +0000</pubDate><guid>/posts/2021/10/04/spice.ai-v0.2-alpha-is-now-available/</guid><description>
&lt;p>We are excited to announce the release of Spice.ai v0.2-alpha! ðŸŽ‰&lt;/p>
&lt;p>This release is the first major version since the &lt;a href="https://blog.spiceai.org/posts/2021/09/07/introducing-spice.ai-open-source-time-series-ai-for-developers/">initial v0.1 announcement&lt;/a> and includes significant improvements based upon community and customer feedback. If you are new to Spice.ai, check out the &lt;a href="https://docs.spiceai.org/getting-started/">getting started guide&lt;/a> and star &lt;a href="https://github.com/spiceai/spiceai">spiceai/spiceai&lt;/a> on GitHub.&lt;/p>
&lt;h2 id="highlights-in-v02-alpha">Highlights in v0.2-alpha&lt;/h2>
&lt;h3 id="tagged-data">Tagged data&lt;/h3>
&lt;p>In the first release, the runtime and AI engine could only ingest numerical data. In v0.2, tagged data is accepted and automatically encoded into fields available for learning. For example, it&amp;rsquo;s now possible to include a &amp;ldquo;liked&amp;rdquo; tag when using tweet data, automatically encoded to a 0/1 field for training. Both CSV and the new &lt;a href="https://github.com/spiceai/data-components-contrib/blob/trunk/dataprocessors/json/README.md">JSON&lt;/a> observation formats support tags. The v0.3 release will add additional support for sets of categorical data.&lt;/p>
&lt;h3 id="streaming-data">Streaming data&lt;/h3>
&lt;p>Previously, the runtime would trigger each &lt;a href="https://github.com/spiceai/data-components-contrib/blob/trunk/dataconnectors/README.md">data connector&lt;/a> to fetch on a 15-second interval. In v0.2, we upgraded the &lt;a href="https://github.com/spiceai/data-components-contrib/blob/trunk/dataconnectors/dataconnector.go">interface for data connectors&lt;/a> to a push/streaming model, which enables continuous streaming data into the environment and AI engine.&lt;/p>
&lt;h3 id="interpreted-data">Interpreted data&lt;/h3>
&lt;p>&lt;a href="http://Spice.ai">Spice.ai&lt;/a> works together with your application code and works best when it&amp;rsquo;s provided continuous feedback. This feedback could be from the application itself, for example, ratings, likes, thumbs-up/down, profit from trades, or external expertise. The &lt;a href="https://docs.spiceai.org/concepts/interpretations">interpretations API&lt;/a> was &lt;a href="https://github.com/spiceai/spiceai/blob/trunk/docs/release_notes/v0.1.1-alpha.md">introduced in v0.1.1&lt;/a>, and v0.2 adds AI engine support providing a way to give meaning or an interpretation of ranges of time-series data, which are then available within reward functions. For example, a time range of stock prices could be a &amp;ldquo;good time to buy,&amp;rdquo; or perhaps Tuesday mornings is a &amp;ldquo;good time to tweet,&amp;rdquo; and an application or expert can teach the AI engine this through interpretations providing a shortcut to it&amp;rsquo;s learning.&lt;/p>
&lt;h2 id="new-in-this-release">New in this release&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Adds&lt;/strong> core runtime and AI engine tagged data support&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> tagged data support to the CSV processor&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> streaming data support to the engine and data connectors&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> a new &lt;a href="https://github.com/spiceai/data-components-contrib/blob/trunk/dataprocessors/json/README.md">JSON data processor&lt;/a> for ingesting JSON data&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> a new &lt;a href="https://github.com/spiceai/data-components-contrib/blob/trunk/dataconnectors/twitter/twitter.go">Twitter data connector&lt;/a> with JSON processor support&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> a new &lt;code>/pods//dataspaces&lt;/code> API&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> support for using interpretations in reward functions &lt;a href="https://docs.spiceai.org/concepts/interpretations">Learn more&lt;/a>.&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> support for downloading zipped pods from the &lt;a href="http://spicerack.org">spicerack.org&lt;/a> registry&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> support for adding data along with the pod manifest when adding a pod from the &lt;a href="http://spicerack.org">spicerack.org&lt;/a> registry&lt;/li>
&lt;li>&lt;strong>Adds&lt;/strong> basic &lt;code>/pods//diagnostics&lt;/code> API&lt;/li>
&lt;li>&lt;strong>Fixes&lt;/strong> pod period, interval, and granularity not being correctly set when trying to use a &amp;ldquo;d&amp;rdquo; format&lt;/li>
&lt;li>&lt;strong>Fixes&lt;/strong> the color scheme of action counts in the dashboard to improve readability&lt;/li>
&lt;/ul>
&lt;h2 id="resources">Resources&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://docs.spiceai.org/getting-started/">Getting started with Spice.ai&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.spiceai.org/">Documentation&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/spiceai/quickstarts/blob/trunk/README.md">Quickstarts&lt;/a> and &lt;a href="https://github.com/spiceai/samples/blob/trunk/README.md">Samples&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="community">Community&lt;/h2>
&lt;p>Spice.ai started with the vision to make AI easy for developers. We are building Spice.ai in the open and with the community. Reach out on Discord or by email to get involved. We will also be starting a community call series soon!&lt;/p>
&lt;ul>
&lt;li>Discord: &lt;a href="https://discord.gg/kZnTfneP5u">https://discord.gg/kZnTfneP5u&lt;/a>&lt;/li>
&lt;li>Reddit: &lt;a href="https://www.reddit.com/r/spiceai">https://www.reddit.com/r/spiceai&lt;/a>&lt;/li>
&lt;li>Twitter: &lt;a href="https://twitter.com/spiceaihq">@SpiceAIHQ&lt;/a>&lt;/li>
&lt;li>Email: &lt;a href="mailto:hey@spiceai.io">hey@spiceai.io&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Posts: Introducing Spice.ai - open source, time series AI for developers</title><link>/posts/2021/09/07/introducing-spice.ai-open-source-time-series-ai-for-developers/</link><pubDate>Tue, 07 Sep 2021 00:00:00 +0000</pubDate><guid>/posts/2021/09/07/introducing-spice.ai-open-source-time-series-ai-for-developers/</guid><description>
&lt;p>AI has recently seen some impressive advances, like with OpenAI &lt;a href="https://openai.com/blog/openai-codex/">Codex&lt;/a> and DeepMind &lt;a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">AlphaFold 2&lt;/a>. And at the same time, for most developers, leveraging AI to create intelligent applications is still way too hard. The &lt;a href="https://hackernoon.com/the-ai-hierarchy-of-needs-18f111fcc007">Data Science Hierarchy of Needs&lt;/a> pyramid from 2017 &lt;em>still&lt;/em> illustrates it well; there are too many unmet needs in applying ML in applications.&lt;/p>
&lt;p>We faced the same AI development challenges many developers do, even though we had years of engineering experience at Microsoft and GitHub, there was too much to learn and build. And we simply didn&amp;rsquo;t have the time, resources, or tools to learn and utilize AI effectively in the project. After experiencing this pain ourselves, we saw an opportunity to make it better for everyone.&lt;/p>
&lt;p>Today, we are making &lt;a href="https://spiceai.org/">Spice.ai&lt;/a> available on GitHub, a new open source project that helps developers use deep learning to create intelligent applications. We&amp;rsquo;re looking for feedback on the direction. It&amp;rsquo;s not finished, in fact, we only started this summer, and we invite you to try out the alpha.&lt;/p>
&lt;div style="display: flex; justify-content: center;">
&lt;img style="max-width: 600px;" width="100%" src="https://res.craft.do/user/full/f6ea57b9-4723-ca7b-aa16-e2a916601d59/doc/E951CFE6-D24A-4C02-A796-FFFCFC5FD5A9/A1AAFFBD-0AE9-47B5-AC9C-D37A6932CE5B_2/screen.png" />
&lt;/div>
&lt;p style="text-align: center;">
&lt;i>Figure 1. Adding a Spice.ai pod, training and getting a recommendation in three commands&lt;/i>
&lt;/p>
&lt;p>Like many developer stories, it all started with a side-project. We were interested in &lt;a href="https://en.wikipedia.org/wiki/Neurofeedback">neurofeedback&lt;/a>, a type of biofeedback therapy that reinforces healthy brain function but can cost up to $15,000. We wanted to make it accessible to more people, so we set out to build a system that leverages AI to deliver neurofeedback more cost-effectively. Using AI for the application was much more challenging than expected, and this sparked the inspiration for Spice.ai.&lt;/p>
&lt;p>In the neurofeedback project, we worked with brain activity &lt;a href="https://en.wikipedia.org/wiki/Electroencephalographyhttps://en.wikipedia.org/wiki/Electroencephalography">EEG&lt;/a> data - time series data. We realized that time series data applies to many domains, from health and biometrics to finance, sales, logistics, security, IoT, and application monitoring. The amount of time series data in these fields is growing exponentially, and extracting insights from this data to make more intelligent software will determine the success of the next generation of applications.&lt;/p>
&lt;p>We also realized that handling time series data is often sensitive, such as with health, financial, and security data. Instead of sending all data into a 3rd-party AI service, we needed the choice to bring the AI runtime to wherever our data and compute lived, either in the cloud, on-premises or on edge devices.&lt;/p>
&lt;h3 id="spiceai---a-modern-development-experience-and-open-source-runtime-for-deep-learning-on-time-series-data">Spice.ai - a modern development experience and open source runtime for deep learning on time series data&lt;/h3>
&lt;p>Spice.ai is an open source, portable runtime for training and using deep learning on time series data. It&amp;rsquo;s written in Golang and Python and runs as a container or microservice with applications calling a simple HTTP API. It&amp;rsquo;s deployable to any public cloud, on-premises, and edge.&lt;/p>
&lt;p>The vision for Spice.ai is to make creating intelligent applications as easy as possible for developers in their development environment of choice. Spice.ai brings AI development to their editor in any language or framework with a fast, iterative, inner development loop, continuous-integration (CI), and continuous-deployment (CD) workflows.&lt;/p>
&lt;p>The Spice.ai runtime also includes a library of &lt;a href="https://github.com/spiceai/data-components-contrib">community-driven components&lt;/a> for streaming and processing time series data, enabling developers to quickly and easily combine data with learning to create intelligent models.&lt;/p>
&lt;p>Developers can write easy-to-understand and re-useable, &amp;ldquo;pods,&amp;rdquo; with manifests that connect these data components with a simple definition of the learning environment. These pods also serve as a package for the resulting trained model.&lt;/p>
&lt;p>Modern developers build together with the community by leveraging registries such as npm, NuGet, and pip. The registry for sharing and using pods is &lt;a href="https://spicerack.org">spicerack.org&lt;/a>. As the community shares more and more pods, developers can quickly build upon each others' work, initially by sharing manifests and eventually by reusing fully-trained models.&lt;/p>
&lt;h3 id="applying-spiceai-to-real-world-problems">Applying Spice.ai to real-world problems&lt;/h3>
&lt;p>We are currently piloting Spice.ai with several companies to create the next generation of modern applications, such as optimizing in-store pickups for a large online retailer or scheduling optimizations for healthcare workers and resources. We&amp;rsquo;ve already seen some cool use cases, including suspicious login detection, intelligent cloud-spend analysis, and order routing for a food delivery app.&lt;/p>
&lt;h3 id="learn-more-and-contribute">Learn more and contribute&lt;/h3>
&lt;p>Building intelligent apps that leverage AI is still way too hard, even for advanced developers. Our mission is to make this as easy as creating a modern web page.&lt;/p>
&lt;p>This mission is a huge undertaking and Spice.ai v0.1-alpha has many gaps, including limited deep learning algorithms and training scale, streaming data, simulated environments, and offline learning modes. Pods aren&amp;rsquo;t searchable or even listed on &lt;a href="http://spicerack.org">spicerack.org&lt;/a> yet. But if the vision resonates with you, join us! Our &lt;a href="https://github.com/spiceai/spiceai/blob/trunk/docs/ROADMAP.md">Spice.ai Roadmap&lt;/a> is public, and now that we have launched, the project and work are open for collaboration.&lt;/p>
&lt;p>If you are interested in partnering, we&amp;rsquo;d love to talk. Try out &lt;a href="https://spiceai.org">Spice.ai&lt;/a>, &lt;a href="mailto:hey@spiceai.io">email us&lt;/a> &amp;ldquo;hey,&amp;rdquo; get in touch on &lt;a href="https://discord.com/channels/803820740868571196/803820740868571199">Discord&lt;/a>, or reach out on &lt;a href="https://twitter.com/0xlukekim">Twitter&lt;/a>.&lt;/p>
&lt;p>We are just getting started! ðŸš€&lt;/p>
&lt;p>&lt;a href="https://twitter.com/0xlukekim">Luke&lt;/a>, &lt;a href="https://twitter.com/leblancphill">Phillip&lt;/a>, and &lt;a href="https://twitter.com/lanesharris">Lane&lt;/a> - Spice.ai project founders&lt;/p></description></item></channel></rss>